25/12/12 03:29:21 INFO SparkContext: Running Spark version 3.5.0
25/12/12 03:29:21 INFO SparkContext: OS info Linux, 6.12.54-linuxkit, aarch64
25/12/12 03:29:21 INFO SparkContext: Java version 11.0.20.1
25/12/12 03:29:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/12/12 03:29:21 INFO ResourceUtils: ==============================================================
25/12/12 03:29:21 INFO ResourceUtils: No custom resources configured for spark.driver.
25/12/12 03:29:21 INFO ResourceUtils: ==============================================================
25/12/12 03:29:21 INFO SparkContext: Submitted application: advdb-q3-df
25/12/12 03:29:21 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/12/12 03:29:21 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
25/12/12 03:29:21 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/12/12 03:29:21 INFO SecurityManager: Changing view acls to: root
25/12/12 03:29:21 INFO SecurityManager: Changing modify acls to: root
25/12/12 03:29:21 INFO SecurityManager: Changing view acls groups to: 
25/12/12 03:29:21 INFO SecurityManager: Changing modify acls groups to: 
25/12/12 03:29:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
25/12/12 03:29:21 INFO Utils: Successfully started service 'sparkDriver' on port 38401.
25/12/12 03:29:21 INFO SparkEnv: Registering MapOutputTracker
25/12/12 03:29:21 INFO SparkEnv: Registering BlockManagerMaster
25/12/12 03:29:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/12/12 03:29:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/12/12 03:29:21 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/12/12 03:29:21 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-47afeb2d-8819-4b9b-bd6a-7f5954b16c21
25/12/12 03:29:21 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/12/12 03:29:21 INFO SparkEnv: Registering OutputCommitCoordinator
25/12/12 03:29:21 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/12/12 03:29:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/12/12 03:29:21 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/12/12 03:29:21 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 17 ms (0 ms spent in bootstraps)
25/12/12 03:29:21 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251212032921-0017
25/12/12 03:29:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251212032921-0017/0 on worker-20251212031329-172.18.0.5-40109 (172.18.0.5:40109) with 1 core(s)
25/12/12 03:29:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20251212032921-0017/0 on hostPort 172.18.0.5:40109 with 1 core(s), 2.0 GiB RAM
25/12/12 03:29:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251212032921-0017/1 on worker-20251212031329-172.18.0.5-40109 (172.18.0.5:40109) with 1 core(s)
25/12/12 03:29:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20251212032921-0017/1 on hostPort 172.18.0.5:40109 with 1 core(s), 2.0 GiB RAM
25/12/12 03:29:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251212032921-0017/2 on worker-20251212031329-172.18.0.5-40109 (172.18.0.5:40109) with 1 core(s)
25/12/12 03:29:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42239.
25/12/12 03:29:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20251212032921-0017/2 on hostPort 172.18.0.5:40109 with 1 core(s), 2.0 GiB RAM
25/12/12 03:29:21 INFO NettyBlockTransferService: Server created on spark-master:42239
25/12/12 03:29:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251212032921-0017/3 on worker-20251212031329-172.18.0.5-40109 (172.18.0.5:40109) with 1 core(s)
25/12/12 03:29:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20251212032921-0017/3 on hostPort 172.18.0.5:40109 with 1 core(s), 2.0 GiB RAM
25/12/12 03:29:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251212032921-0017/4 on worker-20251212031329-172.18.0.5-40109 (172.18.0.5:40109) with 1 core(s)
25/12/12 03:29:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20251212032921-0017/4 on hostPort 172.18.0.5:40109 with 1 core(s), 2.0 GiB RAM
25/12/12 03:29:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/12/12 03:29:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251212032921-0017/5 on worker-20251212031329-172.18.0.5-40109 (172.18.0.5:40109) with 1 core(s)
25/12/12 03:29:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20251212032921-0017/5 on hostPort 172.18.0.5:40109 with 1 core(s), 2.0 GiB RAM
25/12/12 03:29:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251212032921-0017/6 on worker-20251212031329-172.18.0.5-40109 (172.18.0.5:40109) with 1 core(s)
25/12/12 03:29:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20251212032921-0017/6 on hostPort 172.18.0.5:40109 with 1 core(s), 2.0 GiB RAM
25/12/12 03:29:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251212032921-0017/7 on worker-20251212031329-172.18.0.5-40109 (172.18.0.5:40109) with 1 core(s)
25/12/12 03:29:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20251212032921-0017/7 on hostPort 172.18.0.5:40109 with 1 core(s), 2.0 GiB RAM
25/12/12 03:29:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-master, 42239, None)
25/12/12 03:29:21 INFO BlockManagerMasterEndpoint: Registering block manager spark-master:42239 with 434.4 MiB RAM, BlockManagerId(driver, spark-master, 42239, None)
25/12/12 03:29:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-master, 42239, None)
25/12/12 03:29:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, spark-master, 42239, None)
25/12/12 03:29:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251212032921-0017/4 is now RUNNING
25/12/12 03:29:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251212032921-0017/5 is now RUNNING
25/12/12 03:29:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251212032921-0017/6 is now RUNNING
25/12/12 03:29:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251212032921-0017/1 is now RUNNING
25/12/12 03:29:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251212032921-0017/2 is now RUNNING
25/12/12 03:29:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251212032921-0017/7 is now RUNNING
25/12/12 03:29:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251212032921-0017/3 is now RUNNING
25/12/12 03:29:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251212032921-0017/0 is now RUNNING
25/12/12 03:29:22 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
=== Storage Mode: HDFS ===
=== Data Path: hdfs://namenode:9000/data ===
25/12/12 03:29:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/12/12 03:29:22 INFO SharedState: Warehouse path is 'file:/app/spark-warehouse'.
25/12/12 03:29:24 INFO InMemoryFileIndex: It took 117 ms to list leaf files for 2 paths.
25/12/12 03:29:24 INFO InMemoryFileIndex: It took 18 ms to list leaf files for 2 paths.
25/12/12 03:29:26 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:35690) with ID 7,  ResourceProfileId 0
25/12/12 03:29:26 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:35708) with ID 3,  ResourceProfileId 0
25/12/12 03:29:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:36917 with 1048.8 MiB RAM, BlockManagerId(3, 172.18.0.5, 36917, None)
25/12/12 03:29:27 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:35724) with ID 1,  ResourceProfileId 0
25/12/12 03:29:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:45711 with 1048.8 MiB RAM, BlockManagerId(7, 172.18.0.5, 45711, None)
25/12/12 03:29:27 INFO FileSourceStrategy: Pushed Filters: 
25/12/12 03:29:27 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/12/12 03:29:27 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:35740) with ID 6,  ResourceProfileId 0
25/12/12 03:29:27 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:35760) with ID 0,  ResourceProfileId 0
25/12/12 03:29:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:37293 with 1048.8 MiB RAM, BlockManagerId(1, 172.18.0.5, 37293, None)
25/12/12 03:29:27 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:35750) with ID 4,  ResourceProfileId 0
25/12/12 03:29:27 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:35786) with ID 5,  ResourceProfileId 0
25/12/12 03:29:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:40815 with 1048.8 MiB RAM, BlockManagerId(6, 172.18.0.5, 40815, None)
25/12/12 03:29:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:37543 with 1048.8 MiB RAM, BlockManagerId(0, 172.18.0.5, 37543, None)
25/12/12 03:29:27 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:35770) with ID 2,  ResourceProfileId 0
25/12/12 03:29:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:41381 with 1048.8 MiB RAM, BlockManagerId(4, 172.18.0.5, 41381, None)
25/12/12 03:29:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:33289 with 1048.8 MiB RAM, BlockManagerId(5, 172.18.0.5, 33289, None)
25/12/12 03:29:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:35543 with 1048.8 MiB RAM, BlockManagerId(2, 172.18.0.5, 35543, None)
25/12/12 03:29:27 INFO CodeGenerator: Code generated in 108.110125 ms
25/12/12 03:29:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 301.8 KiB, free 434.1 MiB)
25/12/12 03:29:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 53.9 KiB, free 434.1 MiB)
25/12/12 03:29:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-master:42239 (size: 53.9 KiB, free: 434.3 MiB)
25/12/12 03:29:27 INFO SparkContext: Created broadcast 0 from csv at <unknown>:0
25/12/12 03:29:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 118509402 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:29:27 INFO SparkContext: Starting job: csv at <unknown>:0
25/12/12 03:29:27 INFO DAGScheduler: Got job 0 (csv at <unknown>:0) with 1 output partitions
25/12/12 03:29:27 INFO DAGScheduler: Final stage: ResultStage 0 (csv at <unknown>:0)
25/12/12 03:29:27 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:29:27 INFO DAGScheduler: Missing parents: List()
25/12/12 03:29:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0), which has no missing parents
25/12/12 03:29:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 434.0 MiB)
25/12/12 03:29:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.0 MiB)
25/12/12 03:29:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-master:42239 (size: 6.4 KiB, free: 434.3 MiB)
25/12/12 03:29:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
25/12/12 03:29:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:29:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/12/12 03:29:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.5, executor 4, partition 0, ANY, 8249 bytes) 
25/12/12 03:29:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.5:41381 (size: 6.4 KiB, free: 1048.8 MiB)
25/12/12 03:29:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.5:41381 (size: 53.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1092 ms on 172.18.0.5 (executor 4) (1/1)
25/12/12 03:29:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/12/12 03:29:29 INFO DAGScheduler: ResultStage 0 (csv at <unknown>:0) finished in 1.159 s
25/12/12 03:29:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:29:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/12/12 03:29:29 INFO DAGScheduler: Job 0 finished: csv at <unknown>:0, took 1.190980 s
25/12/12 03:29:29 INFO CodeGenerator: Code generated in 19.994917 ms
25/12/12 03:29:29 INFO FileSourceStrategy: Pushed Filters: 
25/12/12 03:29:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/12/12 03:29:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 301.8 KiB, free 433.7 MiB)
25/12/12 03:29:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 53.9 KiB, free 433.7 MiB)
25/12/12 03:29:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-master:42239 (size: 53.9 KiB, free: 434.3 MiB)
25/12/12 03:29:29 INFO SparkContext: Created broadcast 2 from csv at <unknown>:0
25/12/12 03:29:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 118509402 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:29:29 INFO SparkContext: Starting job: csv at <unknown>:0
25/12/12 03:29:29 INFO DAGScheduler: Got job 1 (csv at <unknown>:0) with 8 output partitions
25/12/12 03:29:29 INFO DAGScheduler: Final stage: ResultStage 1 (csv at <unknown>:0)
25/12/12 03:29:29 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:29:29 INFO DAGScheduler: Missing parents: List()
25/12/12 03:29:29 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at <unknown>:0), which has no missing parents
25/12/12 03:29:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 27.9 KiB, free 433.7 MiB)
25/12/12 03:29:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.9 KiB, free 433.6 MiB)
25/12/12 03:29:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on spark-master:42239 (size: 12.9 KiB, free: 434.3 MiB)
25/12/12 03:29:29 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
25/12/12 03:29:29 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:29:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
25/12/12 03:29:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.5, executor 2, partition 0, ANY, 8249 bytes) 
25/12/12 03:29:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.5, executor 3, partition 1, ANY, 8249 bytes) 
25/12/12 03:29:29 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.5, executor 1, partition 2, ANY, 8249 bytes) 
25/12/12 03:29:29 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.5, executor 0, partition 3, ANY, 8249 bytes) 
25/12/12 03:29:29 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.18.0.5, executor 7, partition 4, ANY, 8249 bytes) 
25/12/12 03:29:29 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.18.0.5, executor 6, partition 5, ANY, 8249 bytes) 
25/12/12 03:29:29 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.18.0.5, executor 5, partition 6, ANY, 8249 bytes) 
25/12/12 03:29:29 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.18.0.5, executor 4, partition 7, ANY, 8373 bytes) 
25/12/12 03:29:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:41381 (size: 12.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:36917 (size: 12.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:40815 (size: 12.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:37293 (size: 12.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:35543 (size: 12.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:45711 (size: 12.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:33289 (size: 12.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:37543 (size: 12.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:41381 (size: 53.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:40815 (size: 53.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:45711 (size: 53.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:35543 (size: 53.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:37543 (size: 53.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:37293 (size: 53.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:36917 (size: 53.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:33289 (size: 53.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:36 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 7097 ms on 172.18.0.5 (executor 4) (1/8)
25/12/12 03:29:40 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 10714 ms on 172.18.0.5 (executor 6) (2/8)
25/12/12 03:29:40 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 10723 ms on 172.18.0.5 (executor 5) (3/8)
25/12/12 03:29:40 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 11097 ms on 172.18.0.5 (executor 0) (4/8)
25/12/12 03:29:40 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 11265 ms on 172.18.0.5 (executor 3) (5/8)
25/12/12 03:29:40 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 11297 ms on 172.18.0.5 (executor 7) (6/8)
25/12/12 03:29:40 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 11394 ms on 172.18.0.5 (executor 1) (7/8)
25/12/12 03:29:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 11683 ms on 172.18.0.5 (executor 2) (8/8)
25/12/12 03:29:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/12/12 03:29:40 INFO DAGScheduler: ResultStage 1 (csv at <unknown>:0) finished in 11.704 s
25/12/12 03:29:40 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:29:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/12/12 03:29:40 INFO DAGScheduler: Job 1 finished: csv at <unknown>:0, took 11.713150 s
25/12/12 03:29:41 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
== Physical plan for DataFrame implementation ==
25/12/12 03:29:41 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Mocodes),Not(EqualTo(Mocodes,))
25/12/12 03:29:41 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Mocodes#27),NOT (Mocodes#27 = )
25/12/12 03:29:41 INFO FileSourceStrategy: Pushed Filters: IsNotNull(value)
25/12/12 03:29:41 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(value#82),NOT (regexp_extract(value#82, ^(\S+)\s+(.*)$, 1) = )
== Physical Plan ==
AdaptiveSparkPlan (17)
+- Sort (16)
   +- Exchange (15)
      +- Project (14)
         +- BroadcastHashJoin LeftOuter BuildRight (13)
            :- HashAggregate (8)
            :  +- Exchange (7)
            :     +- HashAggregate (6)
            :        +- Filter (5)
            :           +- Generate (4)
            :              +- Project (3)
            :                 +- Filter (2)
            :                    +- Scan csv  (1)
            +- BroadcastExchange (12)
               +- Project (11)
                  +- Filter (10)
                     +- Scan text  (9)


(1) Scan csv 
Output [1]: [Mocodes#27]
Batched: false
Location: InMemoryFileIndex [hdfs://namenode:9000/data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv, ... 1 entries]
PushedFilters: [IsNotNull(Mocodes), Not(EqualTo(Mocodes,))]
ReadSchema: struct<Mocodes:string>

(2) Filter
Input [1]: [Mocodes#27]
Condition : (isnotnull(Mocodes#27) AND NOT (Mocodes#27 = ))

(3) Project
Output [1]: [regexp_replace(Mocodes#27, \s+,  , 1) AS mocodes_str#75]
Input [1]: [Mocodes#27]

(4) Generate
Input [1]: [mocodes_str#75]
Arguments: explode(split(mocodes_str#75,  , -1)), false, [mocode#78]

(5) Filter
Input [1]: [mocode#78]
Condition : NOT (mocode#78 = )

(6) HashAggregate
Input [1]: [mocode#78]
Keys [1]: [mocode#78]
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#103L]
Results [2]: [mocode#78, count#104L]

(7) Exchange
Input [2]: [mocode#78, count#104L]
Arguments: hashpartitioning(mocode#78, 16), ENSURE_REQUIREMENTS, [plan_id=62]

(8) HashAggregate
Input [2]: [mocode#78, count#104L]
Keys [1]: [mocode#78]
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#90L]
Results [2]: [mocode#78, count(1)#90L AS count#91L]

(9) Scan text 
Output [1]: [value#82]
Batched: false
Location: InMemoryFileIndex [hdfs://namenode:9000/data/MO_codes.txt]
PushedFilters: [IsNotNull(value)]
ReadSchema: struct<value:string>

(10) Filter
Input [1]: [value#82]
Condition : (isnotnull(value#82) AND NOT (regexp_extract(value#82, ^(\S+)\s+(.*)$, 1) = ))

(11) Project
Output [2]: [regexp_extract(value#82, ^(\S+)\s+(.*)$, 1) AS mocode#84, regexp_extract(value#82, ^(\S+)\s+(.*)$, 2) AS mo_desc#85]
Input [1]: [value#82]

(12) BroadcastExchange
Input [2]: [mocode#84, mo_desc#85]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=65]

(13) BroadcastHashJoin
Left keys [1]: [mocode#78]
Right keys [1]: [mocode#84]
Join type: LeftOuter
Join condition: None

(14) Project
Output [3]: [mocode#78 AS MO Code#97, coalesce(mo_desc#85, mocode#78) AS Description#98, count#91L AS Frequency#99L]
Input [4]: [mocode#78, count#91L, mocode#84, mo_desc#85]

(15) Exchange
Input [3]: [MO Code#97, Description#98, Frequency#99L]
Arguments: rangepartitioning(Frequency#99L DESC NULLS LAST, MO Code#97 ASC NULLS FIRST, 16), ENSURE_REQUIREMENTS, [plan_id=69]

(16) Sort
Input [3]: [MO Code#97, Description#98, Frequency#99L]
Arguments: [Frequency#99L DESC NULLS LAST, MO Code#97 ASC NULLS FIRST], true, 0

(17) AdaptiveSparkPlan
Output [3]: [MO Code#97, Description#98, Frequency#99L]
Arguments: isFinalPlan=false


25/12/12 03:29:41 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Mocodes),Not(EqualTo(Mocodes,))
25/12/12 03:29:41 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Mocodes#27),NOT (Mocodes#27 = )
25/12/12 03:29:41 INFO FileSourceStrategy: Pushed Filters: IsNotNull(value)
25/12/12 03:29:41 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(value#82),NOT (regexp_extract(value#82, ^(\S+)\s+(.*)$, 1) = )
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on spark-master:42239 in memory (size: 12.9 KiB, free: 434.3 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:45711 in memory (size: 12.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:40815 in memory (size: 12.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:37293 in memory (size: 12.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:35543 in memory (size: 12.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:36917 in memory (size: 12.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:37543 in memory (size: 12.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:41 INFO CodeGenerator: Code generated in 120.942333 ms
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:33289 in memory (size: 12.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:41 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 301.6 KiB, free 433.4 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:41381 in memory (size: 12.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:41 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 53.7 KiB, free 433.3 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on spark-master:42239 (size: 53.7 KiB, free: 434.2 MiB)
25/12/12 03:29:41 INFO SparkContext: Created broadcast 4 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
25/12/12 03:29:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on spark-master:42239 in memory (size: 53.9 KiB, free: 434.3 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:37293 in memory (size: 53.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:36917 in memory (size: 53.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:41381 in memory (size: 53.9 KiB, free: 1048.7 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:37543 in memory (size: 53.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:45711 in memory (size: 53.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:33289 in memory (size: 53.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:40815 in memory (size: 53.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:35543 in memory (size: 53.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:41 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
25/12/12 03:29:41 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
25/12/12 03:29:41 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
25/12/12 03:29:41 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:29:41 INFO DAGScheduler: Missing parents: List()
25/12/12 03:29:41 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_0_piece0 on spark-master:42239 in memory (size: 53.9 KiB, free: 434.3 MiB)
25/12/12 03:29:41 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.5:41381 in memory (size: 53.9 KiB, free: 1048.8 MiB)
25/12/12 03:29:41 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 17.1 KiB, free 434.0 MiB)
25/12/12 03:29:42 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 434.0 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on spark-master:42239 (size: 7.3 KiB, free: 434.3 MiB)
25/12/12 03:29:42 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
25/12/12 03:29:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:29:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/12/12 03:29:42 INFO CodeGenerator: Code generated in 130.327875 ms
25/12/12 03:29:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.18.0.5, executor 3, partition 0, ANY, 8220 bytes) 
25/12/12 03:29:42 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 301.7 KiB, free 433.7 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Removed broadcast_1_piece0 on spark-master:42239 in memory (size: 6.4 KiB, free: 434.3 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.5:41381 in memory (size: 6.4 KiB, free: 1048.8 MiB)
25/12/12 03:29:42 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 53.8 KiB, free 433.7 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on spark-master:42239 (size: 53.8 KiB, free: 434.3 MiB)
25/12/12 03:29:42 INFO SparkContext: Created broadcast 6 from showString at <unknown>:0
25/12/12 03:29:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 118509402 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.5:36917 (size: 7.3 KiB, free: 1048.8 MiB)
25/12/12 03:29:42 INFO DAGScheduler: Registering RDD 17 (showString at <unknown>:0) as input to shuffle 0
25/12/12 03:29:42 INFO DAGScheduler: Got map stage job 3 (showString at <unknown>:0) with 8 output partitions
25/12/12 03:29:42 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (showString at <unknown>:0)
25/12/12 03:29:42 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:29:42 INFO DAGScheduler: Missing parents: List()
25/12/12 03:29:42 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at showString at <unknown>:0), which has no missing parents
25/12/12 03:29:42 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 47.0 KiB, free 433.6 MiB)
25/12/12 03:29:42 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.7 KiB, free 433.6 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on spark-master:42239 (size: 21.7 KiB, free: 434.3 MiB)
25/12/12 03:29:42 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
25/12/12 03:29:42 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:29:42 INFO TaskSchedulerImpl: Adding task set 3.0 with 8 tasks resource profile 0
25/12/12 03:29:42 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10) (172.18.0.5, executor 0, partition 0, ANY, 8238 bytes) 
25/12/12 03:29:42 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 11) (172.18.0.5, executor 7, partition 1, ANY, 8238 bytes) 
25/12/12 03:29:42 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 12) (172.18.0.5, executor 2, partition 2, ANY, 8238 bytes) 
25/12/12 03:29:42 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 13) (172.18.0.5, executor 1, partition 3, ANY, 8238 bytes) 
25/12/12 03:29:42 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 14) (172.18.0.5, executor 6, partition 4, ANY, 8238 bytes) 
25/12/12 03:29:42 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 15) (172.18.0.5, executor 4, partition 5, ANY, 8238 bytes) 
25/12/12 03:29:42 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 16) (172.18.0.5, executor 5, partition 6, ANY, 8238 bytes) 
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:41381 (size: 21.7 KiB, free: 1048.8 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:45711 (size: 21.7 KiB, free: 1048.8 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:37293 (size: 21.7 KiB, free: 1048.8 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:37543 (size: 21.7 KiB, free: 1048.8 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:33289 (size: 21.7 KiB, free: 1048.8 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.5:36917 (size: 53.7 KiB, free: 1048.7 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:35543 (size: 21.7 KiB, free: 1048.8 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:40815 (size: 21.7 KiB, free: 1048.8 MiB)
25/12/12 03:29:42 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 17) (172.18.0.5, executor 3, partition 7, ANY, 8362 bytes) 
25/12/12 03:29:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 400 ms on 172.18.0.5 (executor 3) (1/1)
25/12/12 03:29:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/12/12 03:29:42 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 0.409 s
25/12/12 03:29:42 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:29:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/12/12 03:29:42 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 0.422799 s
25/12/12 03:29:42 INFO CodeGenerator: Code generated in 15.933751 ms
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:36917 (size: 21.7 KiB, free: 1048.7 MiB)
25/12/12 03:29:42 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 433.6 MiB)
25/12/12 03:29:42 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on spark-master:42239 (size: 23.8 KiB, free: 434.2 MiB)
25/12/12 03:29:42 INFO SparkContext: Created broadcast 8 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
25/12/12 03:29:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:41381 (size: 53.8 KiB, free: 1048.7 MiB)
25/12/12 03:29:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:45711 (size: 53.8 KiB, free: 1048.7 MiB)
25/12/12 03:29:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:37293 (size: 53.8 KiB, free: 1048.7 MiB)
25/12/12 03:29:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:33289 (size: 53.8 KiB, free: 1048.7 MiB)
25/12/12 03:29:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:36917 (size: 53.8 KiB, free: 1048.7 MiB)
25/12/12 03:29:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:35543 (size: 53.8 KiB, free: 1048.7 MiB)
25/12/12 03:29:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:37543 (size: 53.8 KiB, free: 1048.7 MiB)
25/12/12 03:29:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:40815 (size: 53.8 KiB, free: 1048.7 MiB)
25/12/12 03:29:47 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 16) in 5272 ms on 172.18.0.5 (executor 5) (1/8)
25/12/12 03:29:47 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 13) in 5314 ms on 172.18.0.5 (executor 1) (2/8)
25/12/12 03:29:47 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 14) in 5456 ms on 172.18.0.5 (executor 6) (3/8)
25/12/12 03:29:47 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 15) in 5466 ms on 172.18.0.5 (executor 4) (4/8)
25/12/12 03:29:47 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 11) in 5505 ms on 172.18.0.5 (executor 7) (5/8)
25/12/12 03:29:47 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 17) in 5296 ms on 172.18.0.5 (executor 3) (6/8)
25/12/12 03:29:47 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 5675 ms on 172.18.0.5 (executor 0) (7/8)
25/12/12 03:29:47 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 12) in 5740 ms on 172.18.0.5 (executor 2) (8/8)
25/12/12 03:29:47 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/12/12 03:29:47 INFO DAGScheduler: ShuffleMapStage 3 (showString at <unknown>:0) finished in 5.763 s
25/12/12 03:29:47 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:29:47 INFO DAGScheduler: running: Set()
25/12/12 03:29:47 INFO DAGScheduler: waiting: Set()
25/12/12 03:29:47 INFO DAGScheduler: failed: Set()
25/12/12 03:29:47 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/12/12 03:29:47 INFO CodeGenerator: Code generated in 21.813542 ms
25/12/12 03:29:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/12/12 03:29:48 INFO CodeGenerator: Code generated in 16.396458 ms
25/12/12 03:29:48 INFO SparkContext: Starting job: showString at <unknown>:0
25/12/12 03:29:48 INFO DAGScheduler: Got job 4 (showString at <unknown>:0) with 1 output partitions
25/12/12 03:29:48 INFO DAGScheduler: Final stage: ResultStage 5 (showString at <unknown>:0)
25/12/12 03:29:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/12/12 03:29:48 INFO DAGScheduler: Missing parents: List()
25/12/12 03:29:48 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at showString at <unknown>:0), which has no missing parents
25/12/12 03:29:48 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 55.3 KiB, free 433.5 MiB)
25/12/12 03:29:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 25.6 KiB, free 433.5 MiB)
25/12/12 03:29:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on spark-master:42239 (size: 25.6 KiB, free: 434.2 MiB)
25/12/12 03:29:48 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
25/12/12 03:29:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:29:48 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/12/12 03:29:48 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 18) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 7619 bytes) 
25/12/12 03:29:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.5:37293 (size: 25.6 KiB, free: 1048.7 MiB)
25/12/12 03:29:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.5:35724
25/12/12 03:29:48 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.5:37293 (size: 23.8 KiB, free: 1048.7 MiB)
25/12/12 03:29:48 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 18) in 373 ms on 172.18.0.5 (executor 1) (1/1)
25/12/12 03:29:48 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/12/12 03:29:48 INFO DAGScheduler: ResultStage 5 (showString at <unknown>:0) finished in 0.393 s
25/12/12 03:29:48 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:29:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/12/12 03:29:48 INFO DAGScheduler: Job 4 finished: showString at <unknown>:0, took 0.400753 s
25/12/12 03:29:48 INFO CodeGenerator: Code generated in 7.238334 ms
25/12/12 03:29:48 INFO CodeGenerator: Code generated in 11.958125 ms
+-------+---------------------------+---------+
|MO Code|Description                |Frequency|
+-------+---------------------------+---------+
|0344   |Removes vict property      |1002900  |
|1822   |Stranger                   |548422   |
|0416   |Hit-Hit w/ weapon          |404773   |
|0329   |Vandalized                 |377536   |
|0913   |Victim knew Suspect        |278618   |
|2000   |Domestic violence          |256188   |
|1300   |Vehicle involved           |219082   |
|0400   |Force used                 |213165   |
|1402   |Evidence Booked (any crime)|177470   |
|1609   |Smashed                    |131229   |
+-------+---------------------------+---------+
only showing top 10 rows

Execution time for df: 25.95576 seconds
25/12/12 03:29:48 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/12/12 03:29:48 INFO SparkUI: Stopped Spark web UI at http://spark-master:4040
25/12/12 03:29:48 INFO StandaloneSchedulerBackend: Shutting down all executors
25/12/12 03:29:48 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/12/12 03:29:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/12/12 03:29:48 INFO MemoryStore: MemoryStore cleared
25/12/12 03:29:48 INFO BlockManager: BlockManager stopped
25/12/12 03:29:48 INFO BlockManagerMaster: BlockManagerMaster stopped
25/12/12 03:29:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/12/12 03:29:48 INFO SparkContext: Successfully stopped SparkContext
25/12/12 03:29:48 INFO ShutdownHookManager: Shutdown hook called
25/12/12 03:29:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-8f3216be-42a6-4fa8-bddd-95d5fbe81e64
25/12/12 03:29:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc0af2f3-fa1d-4ebf-8310-6b517035c583/pyspark-a30761ea-5ee9-40f7-940d-91db22a9aad3
25/12/12 03:29:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc0af2f3-fa1d-4ebf-8310-6b517035c583
