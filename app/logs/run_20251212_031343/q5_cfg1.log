:: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /root/.ivy2/cache
The jars for the packages stored in: /root/.ivy2/jars
org.apache.sedona#sedona-spark-3.5_2.12 added as a dependency
org.datasyslab#geotools-wrapper added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-9c5f6ea8-32ca-4dfd-bb4f-1d01a9ed6a62;1.0
	confs: [default]
	found org.apache.sedona#sedona-spark-3.5_2.12;1.8.0 in central
	found org.apache.sedona#sedona-common;1.8.0 in central
	found org.apache.commons#commons-math3;3.6.1 in central
	found org.locationtech.jts#jts-core;1.20.0 in central
	found org.wololo#jts2geojson;0.16.1 in central
	found org.locationtech.spatial4j#spatial4j;0.8 in central
	found org.datasyslab#s2-geometry-library;20250620-rc1 in central
	found com.google.errorprone#error_prone_annotations;2.19.1 in central
	found com.google.guava#guava;33.4.7-jre in central
	found com.google.guava#failureaccess;1.0.3 in central
	found com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central
	found org.jspecify#jspecify;1.0.0 in central
	found com.google.j2objc#j2objc-annotations;3.0.0 in central
	found com.google.jsinterop#jsinterop-annotations;2.0.0 in central
	found it.unimi.dsi#fastutil;8.5.15 in central
	found com.uber#h3;4.1.1 in central
	found net.sf.geographiclib#GeographicLib-Java;1.52 in central
	found com.github.ben-manes.caffeine#caffeine;2.9.2 in central
	found org.checkerframework#checker-qual;3.10.0 in central
	found org.apache.sedona#sedona-spark-common-3.5_2.12;1.8.0 in central
	found org.apache.sedona#shade-proto;1.8.0 in central
	found org.xerial#sqlite-jdbc;3.41.2.2 in central
	found io.graphframes#graphframes-spark3_2.12;0.9.2 in central
	found org.scala-lang.modules#scala-collection-compat_2.12;2.5.0 in central
	found org.beryx#awt-color-factory;1.0.0 in central
	found com.wherobots#jpostal;1.2.2 in central
	found org.datasyslab#geotools-wrapper;1.8.0-33.1 in central
:: resolution report :: resolve 353ms :: artifacts dl 27ms
	:: modules in use:
	com.github.ben-manes.caffeine#caffeine;2.9.2 from central in [default]
	com.google.errorprone#error_prone_annotations;2.19.1 from central in [default]
	com.google.guava#failureaccess;1.0.3 from central in [default]
	com.google.guava#guava;33.4.7-jre from central in [default]
	com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]
	com.google.j2objc#j2objc-annotations;3.0.0 from central in [default]
	com.google.jsinterop#jsinterop-annotations;2.0.0 from central in [default]
	com.uber#h3;4.1.1 from central in [default]
	com.wherobots#jpostal;1.2.2 from central in [default]
	io.graphframes#graphframes-spark3_2.12;0.9.2 from central in [default]
	it.unimi.dsi#fastutil;8.5.15 from central in [default]
	net.sf.geographiclib#GeographicLib-Java;1.52 from central in [default]
	org.apache.commons#commons-math3;3.6.1 from central in [default]
	org.apache.sedona#sedona-common;1.8.0 from central in [default]
	org.apache.sedona#sedona-spark-3.5_2.12;1.8.0 from central in [default]
	org.apache.sedona#sedona-spark-common-3.5_2.12;1.8.0 from central in [default]
	org.apache.sedona#shade-proto;1.8.0 from central in [default]
	org.beryx#awt-color-factory;1.0.0 from central in [default]
	org.checkerframework#checker-qual;3.10.0 from central in [default]
	org.datasyslab#geotools-wrapper;1.8.0-33.1 from central in [default]
	org.datasyslab#s2-geometry-library;20250620-rc1 from central in [default]
	org.jspecify#jspecify;1.0.0 from central in [default]
	org.locationtech.jts#jts-core;1.20.0 from central in [default]
	org.locationtech.spatial4j#spatial4j;0.8 from central in [default]
	org.scala-lang.modules#scala-collection-compat_2.12;2.5.0 from central in [default]
	org.wololo#jts2geojson;0.16.1 from central in [default]
	org.xerial#sqlite-jdbc;3.41.2.2 from central in [default]
	:: evicted modules:
	com.google.errorprone#error_prone_annotations;2.36.0 by [com.google.errorprone#error_prone_annotations;2.19.1] in [default]
	com.google.errorprone#error_prone_annotations;2.5.1 by [com.google.errorprone#error_prone_annotations;2.19.1] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   29  |   0   |   0   |   2   ||   27  |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-9c5f6ea8-32ca-4dfd-bb4f-1d01a9ed6a62
	confs: [default]
	0 artifacts copied, 27 already retrieved (0kB/7ms)
25/12/12 03:21:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
/app/src/q5.py:6: DeprecationWarning: Importing from 'sedona.register' is deprecated. Please use 'sedona.spark.register.geo_registrator' instead.
  from sedona.register import SedonaRegistrator
25/12/12 03:21:11 INFO SparkContext: Running Spark version 3.5.0
25/12/12 03:21:11 INFO SparkContext: OS info Linux, 6.12.54-linuxkit, aarch64
25/12/12 03:21:11 INFO SparkContext: Java version 11.0.20.1
25/12/12 03:21:12 INFO ResourceUtils: ==============================================================
25/12/12 03:21:12 INFO ResourceUtils: No custom resources configured for spark.driver.
25/12/12 03:21:12 INFO ResourceUtils: ==============================================================
25/12/12 03:21:12 INFO SparkContext: Submitted application: advdb-q5-dataframe
25/12/12 03:21:12 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 4, script: , vendor: , memory -> name: memory, amount: 8192, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/12/12 03:21:12 INFO ResourceProfile: Limiting resource is cpus at 4 tasks per executor
25/12/12 03:21:12 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/12/12 03:21:12 INFO SecurityManager: Changing view acls to: root
25/12/12 03:21:12 INFO SecurityManager: Changing modify acls to: root
25/12/12 03:21:12 INFO SecurityManager: Changing view acls groups to: 
25/12/12 03:21:12 INFO SecurityManager: Changing modify acls groups to: 
25/12/12 03:21:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
25/12/12 03:21:12 INFO Utils: Successfully started service 'sparkDriver' on port 41353.
25/12/12 03:21:12 INFO SparkEnv: Registering MapOutputTracker
25/12/12 03:21:12 INFO SparkEnv: Registering BlockManagerMaster
25/12/12 03:21:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/12/12 03:21:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/12/12 03:21:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/12/12 03:21:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0f4fa40c-ea8e-4ba8-9b12-483f8eb508f0
25/12/12 03:21:12 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/12/12 03:21:12 INFO SparkEnv: Registering OutputCommitCoordinator
25/12/12 03:21:12 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/12/12 03:21:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.sedona_sedona-spark-3.5_2.12-1.8.0.jar at spark://spark-master:41353/jars/org.apache.sedona_sedona-spark-3.5_2.12-1.8.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.datasyslab_geotools-wrapper-1.8.0-33.1.jar at spark://spark-master:41353/jars/org.datasyslab_geotools-wrapper-1.8.0-33.1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.sedona_sedona-common-1.8.0.jar at spark://spark-master:41353/jars/org.apache.sedona_sedona-common-1.8.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.sedona_sedona-spark-common-3.5_2.12-1.8.0.jar at spark://spark-master:41353/jars/org.apache.sedona_sedona-spark-common-3.5_2.12-1.8.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.locationtech.jts_jts-core-1.20.0.jar at spark://spark-master:41353/jars/org.locationtech.jts_jts-core-1.20.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.wololo_jts2geojson-0.16.1.jar at spark://spark-master:41353/jars/org.wololo_jts2geojson-0.16.1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar at spark://spark-master:41353/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.commons_commons-math3-3.6.1.jar at spark://spark-master:41353/jars/org.apache.commons_commons-math3-3.6.1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.locationtech.spatial4j_spatial4j-0.8.jar at spark://spark-master:41353/jars/org.locationtech.spatial4j_spatial4j-0.8.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.datasyslab_s2-geometry-library-20250620-rc1.jar at spark://spark-master:41353/jars/org.datasyslab_s2-geometry-library-20250620-rc1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.uber_h3-4.1.1.jar at spark://spark-master:41353/jars/com.uber_h3-4.1.1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/net.sf.geographiclib_GeographicLib-Java-1.52.jar at spark://spark-master:41353/jars/net.sf.geographiclib_GeographicLib-Java-1.52.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.github.ben-manes.caffeine_caffeine-2.9.2.jar at spark://spark-master:41353/jars/com.github.ben-manes.caffeine_caffeine-2.9.2.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.errorprone_error_prone_annotations-2.19.1.jar at spark://spark-master:41353/jars/com.google.errorprone_error_prone_annotations-2.19.1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.guava_guava-33.4.7-jre.jar at spark://spark-master:41353/jars/com.google.guava_guava-33.4.7-jre.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.jsinterop_jsinterop-annotations-2.0.0.jar at spark://spark-master:41353/jars/com.google.jsinterop_jsinterop-annotations-2.0.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/it.unimi.dsi_fastutil-8.5.15.jar at spark://spark-master:41353/jars/it.unimi.dsi_fastutil-8.5.15.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.guava_failureaccess-1.0.3.jar at spark://spark-master:41353/jars/com.google.guava_failureaccess-1.0.3.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar at spark://spark-master:41353/jars/com.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.jspecify_jspecify-1.0.0.jar at spark://spark-master:41353/jars/org.jspecify_jspecify-1.0.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.j2objc_j2objc-annotations-3.0.0.jar at spark://spark-master:41353/jars/com.google.j2objc_j2objc-annotations-3.0.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.checkerframework_checker-qual-3.10.0.jar at spark://spark-master:41353/jars/org.checkerframework_checker-qual-3.10.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.sedona_shade-proto-1.8.0-shaded.jar at spark://spark-master:41353/jars/org.apache.sedona_shade-proto-1.8.0-shaded.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.xerial_sqlite-jdbc-3.41.2.2.jar at spark://spark-master:41353/jars/org.xerial_sqlite-jdbc-3.41.2.2.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/io.graphframes_graphframes-spark3_2.12-0.9.2.jar at spark://spark-master:41353/jars/io.graphframes_graphframes-spark3_2.12-0.9.2.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.beryx_awt-color-factory-1.0.0.jar at spark://spark-master:41353/jars/org.beryx_awt-color-factory-1.0.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.wherobots_jpostal-1.2.2.jar at spark://spark-master:41353/jars/com.wherobots_jpostal-1.2.2.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.sedona_sedona-spark-3.5_2.12-1.8.0.jar at spark://spark-master:41353/files/org.apache.sedona_sedona-spark-3.5_2.12-1.8.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.apache.sedona_sedona-spark-3.5_2.12-1.8.0.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.apache.sedona_sedona-spark-3.5_2.12-1.8.0.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.datasyslab_geotools-wrapper-1.8.0-33.1.jar at spark://spark-master:41353/files/org.datasyslab_geotools-wrapper-1.8.0-33.1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.datasyslab_geotools-wrapper-1.8.0-33.1.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.datasyslab_geotools-wrapper-1.8.0-33.1.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.sedona_sedona-common-1.8.0.jar at spark://spark-master:41353/files/org.apache.sedona_sedona-common-1.8.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.apache.sedona_sedona-common-1.8.0.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.apache.sedona_sedona-common-1.8.0.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.sedona_sedona-spark-common-3.5_2.12-1.8.0.jar at spark://spark-master:41353/files/org.apache.sedona_sedona-spark-common-3.5_2.12-1.8.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.apache.sedona_sedona-spark-common-3.5_2.12-1.8.0.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.apache.sedona_sedona-spark-common-3.5_2.12-1.8.0.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.locationtech.jts_jts-core-1.20.0.jar at spark://spark-master:41353/files/org.locationtech.jts_jts-core-1.20.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.locationtech.jts_jts-core-1.20.0.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.locationtech.jts_jts-core-1.20.0.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.wololo_jts2geojson-0.16.1.jar at spark://spark-master:41353/files/org.wololo_jts2geojson-0.16.1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.wololo_jts2geojson-0.16.1.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.wololo_jts2geojson-0.16.1.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar at spark://spark-master:41353/files/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.scala-lang.modules_scala-collection-compat_2.12-2.5.0.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.commons_commons-math3-3.6.1.jar at spark://spark-master:41353/files/org.apache.commons_commons-math3-3.6.1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-math3-3.6.1.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.apache.commons_commons-math3-3.6.1.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.locationtech.spatial4j_spatial4j-0.8.jar at spark://spark-master:41353/files/org.locationtech.spatial4j_spatial4j-0.8.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.locationtech.spatial4j_spatial4j-0.8.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.locationtech.spatial4j_spatial4j-0.8.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.datasyslab_s2-geometry-library-20250620-rc1.jar at spark://spark-master:41353/files/org.datasyslab_s2-geometry-library-20250620-rc1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.datasyslab_s2-geometry-library-20250620-rc1.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.datasyslab_s2-geometry-library-20250620-rc1.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/com.uber_h3-4.1.1.jar at spark://spark-master:41353/files/com.uber_h3-4.1.1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/com.uber_h3-4.1.1.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/com.uber_h3-4.1.1.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/net.sf.geographiclib_GeographicLib-Java-1.52.jar at spark://spark-master:41353/files/net.sf.geographiclib_GeographicLib-Java-1.52.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/net.sf.geographiclib_GeographicLib-Java-1.52.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/net.sf.geographiclib_GeographicLib-Java-1.52.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/com.github.ben-manes.caffeine_caffeine-2.9.2.jar at spark://spark-master:41353/files/com.github.ben-manes.caffeine_caffeine-2.9.2.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/com.github.ben-manes.caffeine_caffeine-2.9.2.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/com.github.ben-manes.caffeine_caffeine-2.9.2.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.errorprone_error_prone_annotations-2.19.1.jar at spark://spark-master:41353/files/com.google.errorprone_error_prone_annotations-2.19.1.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/com.google.errorprone_error_prone_annotations-2.19.1.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/com.google.errorprone_error_prone_annotations-2.19.1.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.guava_guava-33.4.7-jre.jar at spark://spark-master:41353/files/com.google.guava_guava-33.4.7-jre.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/com.google.guava_guava-33.4.7-jre.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/com.google.guava_guava-33.4.7-jre.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.jsinterop_jsinterop-annotations-2.0.0.jar at spark://spark-master:41353/files/com.google.jsinterop_jsinterop-annotations-2.0.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/com.google.jsinterop_jsinterop-annotations-2.0.0.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/com.google.jsinterop_jsinterop-annotations-2.0.0.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/it.unimi.dsi_fastutil-8.5.15.jar at spark://spark-master:41353/files/it.unimi.dsi_fastutil-8.5.15.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/it.unimi.dsi_fastutil-8.5.15.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/it.unimi.dsi_fastutil-8.5.15.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.guava_failureaccess-1.0.3.jar at spark://spark-master:41353/files/com.google.guava_failureaccess-1.0.3.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/com.google.guava_failureaccess-1.0.3.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/com.google.guava_failureaccess-1.0.3.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar at spark://spark-master:41353/files/com.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/com.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/com.google.guava_listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.jspecify_jspecify-1.0.0.jar at spark://spark-master:41353/files/org.jspecify_jspecify-1.0.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.jspecify_jspecify-1.0.0.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.jspecify_jspecify-1.0.0.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.j2objc_j2objc-annotations-3.0.0.jar at spark://spark-master:41353/files/com.google.j2objc_j2objc-annotations-3.0.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/com.google.j2objc_j2objc-annotations-3.0.0.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/com.google.j2objc_j2objc-annotations-3.0.0.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.checkerframework_checker-qual-3.10.0.jar at spark://spark-master:41353/files/org.checkerframework_checker-qual-3.10.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.checkerframework_checker-qual-3.10.0.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.checkerframework_checker-qual-3.10.0.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.sedona_shade-proto-1.8.0-shaded.jar at spark://spark-master:41353/files/org.apache.sedona_shade-proto-1.8.0-shaded.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.apache.sedona_shade-proto-1.8.0-shaded.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.apache.sedona_shade-proto-1.8.0-shaded.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.xerial_sqlite-jdbc-3.41.2.2.jar at spark://spark-master:41353/files/org.xerial_sqlite-jdbc-3.41.2.2.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.xerial_sqlite-jdbc-3.41.2.2.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.xerial_sqlite-jdbc-3.41.2.2.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/io.graphframes_graphframes-spark3_2.12-0.9.2.jar at spark://spark-master:41353/files/io.graphframes_graphframes-spark3_2.12-0.9.2.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/io.graphframes_graphframes-spark3_2.12-0.9.2.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/io.graphframes_graphframes-spark3_2.12-0.9.2.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/org.beryx_awt-color-factory-1.0.0.jar at spark://spark-master:41353/files/org.beryx_awt-color-factory-1.0.0.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/org.beryx_awt-color-factory-1.0.0.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/org.beryx_awt-color-factory-1.0.0.jar
25/12/12 03:21:12 INFO SparkContext: Added file file:///root/.ivy2/jars/com.wherobots_jpostal-1.2.2.jar at spark://spark-master:41353/files/com.wherobots_jpostal-1.2.2.jar with timestamp 1765509671991
25/12/12 03:21:12 INFO Utils: Copying /root/.ivy2/jars/com.wherobots_jpostal-1.2.2.jar to /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/userFiles-75aa425f-c47f-4c94-912b-557a57651c59/com.wherobots_jpostal-1.2.2.jar
25/12/12 03:21:12 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/12/12 03:21:12 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 15 ms (0 ms spent in bootstraps)
25/12/12 03:21:12 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251212032112-0013
25/12/12 03:21:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251212032112-0013/0 on worker-20251212031329-172.18.0.5-40109 (172.18.0.5:40109) with 4 core(s)
25/12/12 03:21:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20251212032112-0013/0 on hostPort 172.18.0.5:40109 with 4 core(s), 8.0 GiB RAM
25/12/12 03:21:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251212032112-0013/1 on worker-20251212031329-172.18.0.5-40109 (172.18.0.5:40109) with 4 core(s)
25/12/12 03:21:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20251212032112-0013/1 on hostPort 172.18.0.5:40109 with 4 core(s), 8.0 GiB RAM
25/12/12 03:21:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41121.
25/12/12 03:21:12 INFO NettyBlockTransferService: Server created on spark-master:41121
25/12/12 03:21:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/12/12 03:21:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-master, 41121, None)
25/12/12 03:21:12 INFO BlockManagerMasterEndpoint: Registering block manager spark-master:41121 with 434.4 MiB RAM, BlockManagerId(driver, spark-master, 41121, None)
25/12/12 03:21:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-master, 41121, None)
25/12/12 03:21:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, spark-master, 41121, None)
25/12/12 03:21:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251212032112-0013/0 is now RUNNING
25/12/12 03:21:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251212032112-0013/1 is now RUNNING
25/12/12 03:21:13 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
=== Storage Mode: HDFS ===
=== Data Path: hdfs://namenode:9000/data ===
/app/src/q5.py:332: DeprecationWarning: Call to deprecated function registerAll (Deprecated since 1.4.1, use SedonaContext.create() instead.).
  SedonaRegistrator.registerAll(spark)
25/12/12 03:21:13 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/12/12 03:21:13 INFO SharedState: Warehouse path is 'file:/app/spark-warehouse'.
25/12/12 03:21:14 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:35906) with ID 1,  ResourceProfileId 0
25/12/12 03:21:14 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:35914) with ID 0,  ResourceProfileId 0
25/12/12 03:21:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:35921 with 4.6 GiB RAM, BlockManagerId(1, 172.18.0.5, 35921, None)
25/12/12 03:21:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:36293 with 4.6 GiB RAM, BlockManagerId(0, 172.18.0.5, 36293, None)
25/12/12 03:21:15 INFO CodeGenerator: Code generated in 143.726417 ms
25/12/12 03:21:15 INFO DAGScheduler: Registering RDD 2 (count at <unknown>:0) as input to shuffle 0
25/12/12 03:21:15 INFO DAGScheduler: Got map stage job 0 (count at <unknown>:0) with 1 output partitions
25/12/12 03:21:15 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at <unknown>:0)
25/12/12 03:21:15 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:15 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:15 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at <unknown>:0), which has no missing parents
25/12/12 03:21:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
25/12/12 03:21:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.4 MiB)
25/12/12 03:21:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-master:41121 (size: 5.7 KiB, free: 434.4 MiB)
25/12/12 03:21:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/12/12 03:21:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 12994 bytes) 
25/12/12 03:21:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.5:35921 (size: 5.7 KiB, free: 4.6 GiB)
25/12/12 03:21:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 616 ms on 172.18.0.5 (executor 1) (1/1)
25/12/12 03:21:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/12/12 03:21:16 INFO DAGScheduler: ShuffleMapStage 0 (count at <unknown>:0) finished in 1.210 s
25/12/12 03:21:16 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:21:16 INFO DAGScheduler: running: Set()
25/12/12 03:21:16 INFO DAGScheduler: waiting: Set()
25/12/12 03:21:16 INFO DAGScheduler: failed: Set()
25/12/12 03:21:16 INFO CodeGenerator: Code generated in 9.673916 ms
25/12/12 03:21:16 INFO SparkContext: Starting job: count at <unknown>:0
25/12/12 03:21:16 INFO DAGScheduler: Got job 1 (count at <unknown>:0) with 1 output partitions
25/12/12 03:21:16 INFO DAGScheduler: Final stage: ResultStage 2 (count at <unknown>:0)
25/12/12 03:21:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
25/12/12 03:21:16 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at <unknown>:0), which has no missing parents
25/12/12 03:21:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.5 KiB, free 434.4 MiB)
25/12/12 03:21:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.4 MiB)
25/12/12 03:21:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-master:41121 (size: 5.9 KiB, free: 434.4 MiB)
25/12/12 03:21:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/12/12 03:21:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 12797 bytes) 
25/12/12 03:21:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.5:36293 (size: 5.9 KiB, free: 4.6 GiB)
25/12/12 03:21:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.5:35914
25/12/12 03:21:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 557 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:21:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/12/12 03:21:17 INFO DAGScheduler: ResultStage 2 (count at <unknown>:0) finished in 0.565 s
25/12/12 03:21:17 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/12/12 03:21:17 INFO DAGScheduler: Job 1 finished: count at <unknown>:0, took 0.575835 s
25/12/12 03:21:17 INFO BlockManagerInfo: Removed broadcast_1_piece0 on spark-master:41121 in memory (size: 5.9 KiB, free: 434.4 MiB)
25/12/12 03:21:17 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.5:36293 in memory (size: 5.9 KiB, free: 4.6 GiB)
25/12/12 03:21:17 INFO BlockManagerInfo: Removed broadcast_0_piece0 on spark-master:41121 in memory (size: 5.7 KiB, free: 434.4 MiB)
25/12/12 03:21:17 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.5:35921 in memory (size: 5.7 KiB, free: 4.6 GiB)
25/12/12 03:21:18 INFO InMemoryFileIndex: It took 43 ms to list leaf files for 2 paths.
25/12/12 03:21:18 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 2 paths.
25/12/12 03:21:19 INFO FileSourceStrategy: Pushed Filters: 
25/12/12 03:21:19 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#19, None)) > 0)
25/12/12 03:21:19 INFO CodeGenerator: Code generated in 9.66525 ms
25/12/12 03:21:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 314.0 KiB, free 434.1 MiB)
25/12/12 03:21:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 57.5 KiB, free 434.0 MiB)
25/12/12 03:21:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-master:41121 (size: 57.5 KiB, free: 434.3 MiB)
25/12/12 03:21:19 INFO SparkContext: Created broadcast 2 from csv at <unknown>:0
25/12/12 03:21:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 118509402 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:21:19 INFO SparkContext: Starting job: csv at <unknown>:0
25/12/12 03:21:19 INFO DAGScheduler: Got job 2 (csv at <unknown>:0) with 1 output partitions
25/12/12 03:21:19 INFO DAGScheduler: Final stage: ResultStage 3 (csv at <unknown>:0)
25/12/12 03:21:19 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:19 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:19 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[9] at csv at <unknown>:0), which has no missing parents
25/12/12 03:21:19 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.5 KiB, free 434.0 MiB)
25/12/12 03:21:19 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.0 MiB)
25/12/12 03:21:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on spark-master:41121 (size: 6.4 KiB, free: 434.3 MiB)
25/12/12 03:21:19 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:19 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/12/12 03:21:19 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.5, executor 1, partition 0, ANY, 13427 bytes) 
25/12/12 03:21:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:35921 (size: 6.4 KiB, free: 4.6 GiB)
25/12/12 03:21:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:35921 (size: 57.5 KiB, free: 4.6 GiB)
25/12/12 03:21:19 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 651 ms on 172.18.0.5 (executor 1) (1/1)
25/12/12 03:21:19 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/12/12 03:21:19 INFO DAGScheduler: ResultStage 3 (csv at <unknown>:0) finished in 0.664 s
25/12/12 03:21:19 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/12/12 03:21:19 INFO DAGScheduler: Job 2 finished: csv at <unknown>:0, took 0.667814 s
25/12/12 03:21:19 INFO CodeGenerator: Code generated in 6.34425 ms
25/12/12 03:21:19 INFO FileSourceStrategy: Pushed Filters: 
25/12/12 03:21:19 INFO FileSourceStrategy: Post-Scan Filters: 
25/12/12 03:21:19 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 314.0 KiB, free 433.7 MiB)
25/12/12 03:21:19 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 57.5 KiB, free 433.7 MiB)
25/12/12 03:21:19 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on spark-master:41121 (size: 57.5 KiB, free: 434.3 MiB)
25/12/12 03:21:19 INFO SparkContext: Created broadcast 4 from csv at <unknown>:0
25/12/12 03:21:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 118509402 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:21:19 INFO SparkContext: Starting job: csv at <unknown>:0
25/12/12 03:21:19 INFO DAGScheduler: Got job 3 (csv at <unknown>:0) with 8 output partitions
25/12/12 03:21:19 INFO DAGScheduler: Final stage: ResultStage 4 (csv at <unknown>:0)
25/12/12 03:21:19 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:19 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:19 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[15] at csv at <unknown>:0), which has no missing parents
25/12/12 03:21:19 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 39.3 KiB, free 433.6 MiB)
25/12/12 03:21:19 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 433.6 MiB)
25/12/12 03:21:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on spark-master:41121 (size: 15.7 KiB, free: 434.3 MiB)
25/12/12 03:21:19 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:19 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:21:19 INFO TaskSchedulerImpl: Adding task set 4.0 with 8 tasks resource profile 0
25/12/12 03:21:19 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.5, executor 0, partition 0, ANY, 13427 bytes) 
25/12/12 03:21:19 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 4) (172.18.0.5, executor 1, partition 1, ANY, 13427 bytes) 
25/12/12 03:21:19 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 5) (172.18.0.5, executor 0, partition 2, ANY, 13427 bytes) 
25/12/12 03:21:19 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 6) (172.18.0.5, executor 1, partition 3, ANY, 13427 bytes) 
25/12/12 03:21:19 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 7) (172.18.0.5, executor 0, partition 4, ANY, 13427 bytes) 
25/12/12 03:21:19 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 8) (172.18.0.5, executor 1, partition 5, ANY, 13427 bytes) 
25/12/12 03:21:19 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 9) (172.18.0.5, executor 0, partition 6, ANY, 13427 bytes) 
25/12/12 03:21:19 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 10) (172.18.0.5, executor 1, partition 7, ANY, 13551 bytes) 
25/12/12 03:21:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.5:35921 (size: 15.7 KiB, free: 4.6 GiB)
25/12/12 03:21:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.5:36293 (size: 15.7 KiB, free: 4.6 GiB)
25/12/12 03:21:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.5:35921 (size: 57.5 KiB, free: 4.6 GiB)
25/12/12 03:21:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.5:36293 (size: 57.5 KiB, free: 4.6 GiB)
25/12/12 03:21:22 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 10) in 2662 ms on 172.18.0.5 (executor 1) (1/8)
25/12/12 03:21:22 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 8) in 2723 ms on 172.18.0.5 (executor 1) (2/8)
25/12/12 03:21:22 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 6) in 2737 ms on 172.18.0.5 (executor 1) (3/8)
25/12/12 03:21:22 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 4) in 2774 ms on 172.18.0.5 (executor 1) (4/8)
25/12/12 03:21:23 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 3465 ms on 172.18.0.5 (executor 0) (5/8)
25/12/12 03:21:23 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 9) in 3465 ms on 172.18.0.5 (executor 0) (6/8)
25/12/12 03:21:23 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 7) in 3489 ms on 172.18.0.5 (executor 0) (7/8)
25/12/12 03:21:23 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 5) in 3500 ms on 172.18.0.5 (executor 0) (8/8)
25/12/12 03:21:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/12/12 03:21:23 INFO DAGScheduler: ResultStage 4 (csv at <unknown>:0) finished in 3.519 s
25/12/12 03:21:23 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/12/12 03:21:23 INFO DAGScheduler: Job 3 finished: csv at <unknown>:0, took 3.524394 s
25/12/12 03:21:23 INFO BlockManagerInfo: Removed broadcast_5_piece0 on spark-master:41121 in memory (size: 15.7 KiB, free: 434.3 MiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.5:36293 in memory (size: 15.7 KiB, free: 4.6 GiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.5:35921 in memory (size: 15.7 KiB, free: 4.6 GiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Removed broadcast_4_piece0 on spark-master:41121 in memory (size: 57.5 KiB, free: 434.3 MiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.5:36293 in memory (size: 57.5 KiB, free: 4.6 GiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.5:35921 in memory (size: 57.5 KiB, free: 4.6 GiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Removed broadcast_3_piece0 on spark-master:41121 in memory (size: 6.4 KiB, free: 434.3 MiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.5:35921 in memory (size: 6.4 KiB, free: 4.6 GiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Removed broadcast_2_piece0 on spark-master:41121 in memory (size: 57.5 KiB, free: 434.4 MiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:35921 in memory (size: 57.5 KiB, free: 4.6 GiB)
25/12/12 03:21:23 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/12/12 03:21:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 314.4 KiB, free 434.1 MiB)
25/12/12 03:21:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 57.4 KiB, free 434.0 MiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on spark-master:41121 (size: 57.4 KiB, free: 434.3 MiB)
25/12/12 03:21:23 INFO SparkContext: Created broadcast 6 from json at <unknown>:0
25/12/12 03:21:23 INFO FileInputFormat: Total input files to process : 1
25/12/12 03:21:23 INFO FileInputFormat: Total input files to process : 1
25/12/12 03:21:23 INFO SparkContext: Starting job: json at <unknown>:0
25/12/12 03:21:23 INFO DAGScheduler: Got job 4 (json at <unknown>:0) with 1 output partitions
25/12/12 03:21:23 INFO DAGScheduler: Final stage: ResultStage 5 (json at <unknown>:0)
25/12/12 03:21:23 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:23 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:23 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[18] at json at <unknown>:0), which has no missing parents
25/12/12 03:21:23 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 9.2 KiB, free 434.0 MiB)
25/12/12 03:21:23 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 434.0 MiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on spark-master:41121 (size: 4.9 KiB, free: 434.3 MiB)
25/12/12 03:21:23 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[18] at json at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:23 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/12/12 03:21:23 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11) (172.18.0.5, executor 1, partition 0, ANY, 12944 bytes) 
25/12/12 03:21:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:35921 (size: 4.9 KiB, free: 4.6 GiB)
25/12/12 03:21:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:35921 (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:21:25 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 1328 ms on 172.18.0.5 (executor 1) (1/1)
25/12/12 03:21:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/12/12 03:21:25 INFO DAGScheduler: ResultStage 5 (json at <unknown>:0) finished in 1.336 s
25/12/12 03:21:25 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/12/12 03:21:25 INFO DAGScheduler: Job 4 finished: json at <unknown>:0, took 1.342827 s
25/12/12 03:21:25 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
25/12/12 03:21:25 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/12/12 03:21:25 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/12/12 03:21:25 INFO FileSourceStrategy: Pushed Filters: 
25/12/12 03:21:25 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#212, None)) > 0)
25/12/12 03:21:25 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 314.0 KiB, free 433.7 MiB)
25/12/12 03:21:25 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 57.4 KiB, free 433.7 MiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on spark-master:41121 (size: 57.4 KiB, free: 434.3 MiB)
25/12/12 03:21:25 INFO SparkContext: Created broadcast 8 from csv at <unknown>:0
25/12/12 03:21:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:21:25 INFO SparkContext: Starting job: csv at <unknown>:0
25/12/12 03:21:25 INFO DAGScheduler: Got job 5 (csv at <unknown>:0) with 1 output partitions
25/12/12 03:21:25 INFO DAGScheduler: Final stage: ResultStage 6 (csv at <unknown>:0)
25/12/12 03:21:25 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:25 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:25 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[22] at csv at <unknown>:0), which has no missing parents
25/12/12 03:21:25 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 13.5 KiB, free 433.6 MiB)
25/12/12 03:21:25 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.6 MiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on spark-master:41121 (size: 6.4 KiB, free: 434.3 MiB)
25/12/12 03:21:25 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[22] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:25 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/12/12 03:21:25 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12) (172.18.0.5, executor 0, partition 0, ANY, 13404 bytes) 
25/12/12 03:21:25 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.5:36293 (size: 6.4 KiB, free: 4.6 GiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.5:36293 (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:21:25 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 77 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:21:25 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/12/12 03:21:25 INFO DAGScheduler: ResultStage 6 (csv at <unknown>:0) finished in 0.084 s
25/12/12 03:21:25 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/12/12 03:21:25 INFO DAGScheduler: Job 5 finished: csv at <unknown>:0, took 0.085965 s
25/12/12 03:21:25 INFO FileSourceStrategy: Pushed Filters: 
25/12/12 03:21:25 INFO FileSourceStrategy: Post-Scan Filters: 
25/12/12 03:21:25 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 314.0 KiB, free 433.3 MiB)
25/12/12 03:21:25 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 57.4 KiB, free 433.3 MiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on spark-master:41121 (size: 57.4 KiB, free: 434.2 MiB)
25/12/12 03:21:25 INFO SparkContext: Created broadcast 10 from csv at <unknown>:0
25/12/12 03:21:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:21:25 INFO BlockManagerInfo: Removed broadcast_6_piece0 on spark-master:41121 in memory (size: 57.4 KiB, free: 434.3 MiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.5:35921 in memory (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on spark-master:41121 in memory (size: 4.9 KiB, free: 434.3 MiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.5:35921 in memory (size: 4.9 KiB, free: 4.6 GiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Removed broadcast_10_piece0 on spark-master:41121 in memory (size: 57.4 KiB, free: 434.3 MiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Removed broadcast_8_piece0 on spark-master:41121 in memory (size: 57.4 KiB, free: 434.4 MiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.5:36293 in memory (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Removed broadcast_9_piece0 on spark-master:41121 in memory (size: 6.4 KiB, free: 434.4 MiB)
25/12/12 03:21:25 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.5:36293 in memory (size: 6.4 KiB, free: 4.6 GiB)
25/12/12 03:21:26 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:21:26 INFO FileSourceStrategy: Post-Scan Filters: (size(features#189, true) > 0),isnotnull(features#189)
25/12/12 03:21:26 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Estimated Median Income),IsNotNull(Zip Code)
25/12/12 03:21:26 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Estimated Median Income#231),isnotnull(Zip Code#229),isnotnull(cast(regexp_replace(Estimated Median Income#231, [$,], , 1) as double))
25/12/12 03:21:26 INFO JoinQueryDetector: Planning spatial join for ST_CONTAINS relationship with swapped left and right shapes
25/12/12 03:21:26 INFO FileSourceStrategy: Pushed Filters: IsNotNull(LAT),IsNotNull(LON),Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)),IsNotNull(DATE OCC)
25/12/12 03:21:26 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(LAT#62),isnotnull(LON#63),NOT (LAT#62 = 0.0),NOT (LON#63 = 0.0),isnotnull(DATE OCC#38),isnotnull(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false))),(year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) >= 2020),(year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) <= 2021),isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )
25/12/12 03:21:26 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:21:26 INFO FileSourceStrategy: Post-Scan Filters: (size(features#279, true) > 0),isnotnull(features#279)
25/12/12 03:21:26 INFO CodeGenerator: Code generated in 41.623167 ms
25/12/12 03:21:26 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 314.0 KiB, free 434.1 MiB)
25/12/12 03:21:26 INFO CodeGenerator: Code generated in 44.396042 ms
25/12/12 03:21:26 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 434.0 MiB)
25/12/12 03:21:26 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 434.3 MiB)
25/12/12 03:21:26 INFO SparkContext: Created broadcast 11 from collect at /app/src/q5.py:175
25/12/12 03:21:26 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 314.0 KiB, free 433.7 MiB)
25/12/12 03:21:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:21:26 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 57.4 KiB, free 433.7 MiB)
25/12/12 03:21:26 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on spark-master:41121 (size: 57.4 KiB, free: 434.3 MiB)
25/12/12 03:21:26 INFO SparkContext: Created broadcast 12 from collect at /app/src/q5.py:175
25/12/12 03:21:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 118509402 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:21:26 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:21:26 INFO DAGScheduler: Got job 6 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:21:26 INFO DAGScheduler: Final stage: ResultStage 7 (collect at /app/src/q5.py:175)
25/12/12 03:21:26 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:26 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:26 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:26 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 19.9 KiB, free 433.7 MiB)
25/12/12 03:21:26 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)
25/12/12 03:21:26 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on spark-master:41121 (size: 9.0 KiB, free: 434.3 MiB)
25/12/12 03:21:26 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:26 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/12/12 03:21:26 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 13) (172.18.0.5, executor 0, partition 0, ANY, 13404 bytes) 
25/12/12 03:21:26 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.5:36293 (size: 9.0 KiB, free: 4.6 GiB)
25/12/12 03:21:26 INFO CodeGenerator: Code generated in 66.260917 ms
25/12/12 03:21:26 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 313.8 KiB, free 433.3 MiB)
25/12/12 03:21:26 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:36293 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:21:26 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 433.3 MiB)
25/12/12 03:21:26 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 434.2 MiB)
25/12/12 03:21:26 INFO SparkContext: Created broadcast 14 from collect at /app/src/q5.py:175
25/12/12 03:21:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 22990761 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:21:26 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:21:26 INFO DAGScheduler: Got job 7 (collect at /app/src/q5.py:175) with 8 output partitions
25/12/12 03:21:26 INFO DAGScheduler: Final stage: ResultStage 8 (collect at /app/src/q5.py:175)
25/12/12 03:21:26 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:26 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:26 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[41] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:26 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 31.2 KiB, free 433.3 MiB)
25/12/12 03:21:26 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 433.2 MiB)
25/12/12 03:21:26 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on spark-master:41121 (size: 14.5 KiB, free: 434.2 MiB)
25/12/12 03:21:26 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:26 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 8 (MapPartitionsRDD[41] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:21:26 INFO TaskSchedulerImpl: Adding task set 8.0 with 8 tasks resource profile 0
25/12/12 03:21:26 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 14) (172.18.0.5, executor 1, partition 0, ANY, 13427 bytes) 
25/12/12 03:21:26 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 15) (172.18.0.5, executor 0, partition 1, ANY, 13427 bytes) 
25/12/12 03:21:26 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 16) (172.18.0.5, executor 1, partition 2, ANY, 13427 bytes) 
25/12/12 03:21:26 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 17) (172.18.0.5, executor 0, partition 3, ANY, 13427 bytes) 
25/12/12 03:21:26 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 18) (172.18.0.5, executor 1, partition 4, ANY, 13427 bytes) 
25/12/12 03:21:26 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 19) (172.18.0.5, executor 0, partition 5, ANY, 13427 bytes) 
25/12/12 03:21:26 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 20) (172.18.0.5, executor 1, partition 6, ANY, 13427 bytes) 
25/12/12 03:21:26 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.5:36293 (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:21:26 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.5:35921 (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:21:26 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 21) (172.18.0.5, executor 0, partition 7, ANY, 13551 bytes) 
25/12/12 03:21:26 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 13) in 220 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:21:26 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/12/12 03:21:26 INFO DAGScheduler: ResultStage 7 (collect at /app/src/q5.py:175) finished in 0.225 s
25/12/12 03:21:26 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/12/12 03:21:26 INFO DAGScheduler: Job 6 finished: collect at /app/src/q5.py:175, took 0.230178 s
25/12/12 03:21:26 INFO CodeGenerator: Code generated in 24.3845 ms
25/12/12 03:21:26 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 433.2 MiB)
25/12/12 03:21:26 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on spark-master:41121 (size: 5.5 KiB, free: 434.2 MiB)
25/12/12 03:21:26 INFO SparkContext: Created broadcast 16 from collect at /app/src/q5.py:175
25/12/12 03:21:27 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.5:36293 (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:21:27 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.5:35921 (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:21:29 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 21) in 3129 ms on 172.18.0.5 (executor 0) (1/8)
25/12/12 03:21:29 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 15) in 3240 ms on 172.18.0.5 (executor 0) (2/8)
25/12/12 03:21:29 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 14) in 3302 ms on 172.18.0.5 (executor 1) (3/8)
25/12/12 03:21:29 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 20) in 3329 ms on 172.18.0.5 (executor 1) (4/8)
25/12/12 03:21:29 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 16) in 3337 ms on 172.18.0.5 (executor 1) (5/8)
25/12/12 03:21:29 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 17) in 3361 ms on 172.18.0.5 (executor 0) (6/8)
25/12/12 03:21:29 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 18) in 3383 ms on 172.18.0.5 (executor 1) (7/8)
25/12/12 03:21:29 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 19) in 3486 ms on 172.18.0.5 (executor 0) (8/8)
25/12/12 03:21:29 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/12/12 03:21:29 INFO DAGScheduler: ResultStage 8 (collect at /app/src/q5.py:175) finished in 3.499 s
25/12/12 03:21:29 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/12/12 03:21:29 INFO DAGScheduler: Job 7 finished: collect at /app/src/q5.py:175, took 3.506342 s
25/12/12 03:21:29 INFO RangeJoinExec: [SedonaSQL] Number of partitions on the left: 8
25/12/12 03:21:29 INFO RangeJoinExec: [SedonaSQL] Number of partitions on the right: 1
25/12/12 03:21:29 INFO RangeJoinExec: [SedonaSQL] Dominant side count: 407488
25/12/12 03:21:29 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:21:29 INFO DAGScheduler: Got job 8 (collect at /app/src/q5.py:175) with 8 output partitions
25/12/12 03:21:29 INFO DAGScheduler: Final stage: ResultStage 9 (collect at /app/src/q5.py:175)
25/12/12 03:21:29 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:29 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:29 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[44] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:29 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 32.1 KiB, free 433.2 MiB)
25/12/12 03:21:29 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 433.2 MiB)
25/12/12 03:21:29 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on spark-master:41121 (size: 15.1 KiB, free: 434.2 MiB)
25/12/12 03:21:29 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:29 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 9 (MapPartitionsRDD[44] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:21:29 INFO TaskSchedulerImpl: Adding task set 9.0 with 8 tasks resource profile 0
25/12/12 03:21:29 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 22) (172.18.0.5, executor 1, partition 0, ANY, 13536 bytes) 
25/12/12 03:21:29 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 23) (172.18.0.5, executor 0, partition 1, ANY, 13536 bytes) 
25/12/12 03:21:29 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 24) (172.18.0.5, executor 1, partition 2, ANY, 13536 bytes) 
25/12/12 03:21:29 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 25) (172.18.0.5, executor 0, partition 3, ANY, 13536 bytes) 
25/12/12 03:21:29 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 26) (172.18.0.5, executor 1, partition 4, ANY, 13536 bytes) 
25/12/12 03:21:29 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 27) (172.18.0.5, executor 0, partition 5, ANY, 13536 bytes) 
25/12/12 03:21:29 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 28) (172.18.0.5, executor 1, partition 6, ANY, 13536 bytes) 
25/12/12 03:21:29 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 29) (172.18.0.5, executor 0, partition 7, ANY, 13660 bytes) 
25/12/12 03:21:29 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.5:36293 (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:21:29 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.5:35921 (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:21:31 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 22) in 1338 ms on 172.18.0.5 (executor 1) (1/8)
25/12/12 03:21:31 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 24) in 1347 ms on 172.18.0.5 (executor 1) (2/8)
25/12/12 03:21:31 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 26) in 1359 ms on 172.18.0.5 (executor 1) (3/8)
25/12/12 03:21:31 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 28) in 1385 ms on 172.18.0.5 (executor 1) (4/8)
25/12/12 03:21:31 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 29) in 1457 ms on 172.18.0.5 (executor 0) (5/8)
25/12/12 03:21:31 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 23) in 1509 ms on 172.18.0.5 (executor 0) (6/8)
25/12/12 03:21:31 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 25) in 1522 ms on 172.18.0.5 (executor 0) (7/8)
25/12/12 03:21:31 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 27) in 1624 ms on 172.18.0.5 (executor 0) (8/8)
25/12/12 03:21:31 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/12/12 03:21:31 INFO DAGScheduler: ResultStage 9 (collect at /app/src/q5.py:175) finished in 1.635 s
25/12/12 03:21:31 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/12/12 03:21:31 INFO DAGScheduler: Job 8 finished: collect at /app/src/q5.py:175, took 1.646886 s
25/12/12 03:21:31 INFO SpatialRDD: Collected 4274 samples
25/12/12 03:21:31 INFO BlockManagerInfo: Removed broadcast_13_piece0 on spark-master:41121 in memory (size: 9.0 KiB, free: 434.2 MiB)
25/12/12 03:21:31 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.18.0.5:36293 in memory (size: 9.0 KiB, free: 4.6 GiB)
25/12/12 03:21:31 INFO BlockManagerInfo: Removed broadcast_17_piece0 on spark-master:41121 in memory (size: 15.1 KiB, free: 434.2 MiB)
25/12/12 03:21:31 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.5:35921 in memory (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:21:31 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.5:36293 in memory (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:21:31 INFO BlockManagerInfo: Removed broadcast_15_piece0 on spark-master:41121 in memory (size: 14.5 KiB, free: 434.2 MiB)
25/12/12 03:21:31 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.5:35921 in memory (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:21:31 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.5:36293 in memory (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:21:31 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.
25/12/12 03:21:31 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 720.0 B, free 433.3 MiB)
25/12/12 03:21:31 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 508.0 B, free 433.3 MiB)
25/12/12 03:21:31 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on spark-master:41121 (size: 508.0 B, free: 434.2 MiB)
25/12/12 03:21:31 INFO SparkContext: Created broadcast 18 from collect at /app/src/q5.py:175
25/12/12 03:21:31 INFO DAGScheduler: Registering RDD 45 (collect at /app/src/q5.py:175) as input to shuffle 3
25/12/12 03:21:31 INFO DAGScheduler: Registering RDD 48 (collect at /app/src/q5.py:175) as input to shuffle 2
25/12/12 03:21:31 INFO DAGScheduler: Registering RDD 56 (collect at /app/src/q5.py:175) as input to shuffle 1
25/12/12 03:21:31 INFO DAGScheduler: Got map stage job 9 (collect at /app/src/q5.py:175) with 12 output partitions
25/12/12 03:21:31 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (collect at /app/src/q5.py:175)
25/12/12 03:21:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10, ShuffleMapStage 11)
25/12/12 03:21:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10, ShuffleMapStage 11)
25/12/12 03:21:31 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[45] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:31 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 35.5 KiB, free 433.3 MiB)
25/12/12 03:21:31 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 433.3 MiB)
25/12/12 03:21:31 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on spark-master:41121 (size: 16.8 KiB, free: 434.2 MiB)
25/12/12 03:21:31 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:31 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[45] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:21:31 INFO TaskSchedulerImpl: Adding task set 10.0 with 8 tasks resource profile 0
25/12/12 03:21:31 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[48] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:31 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 30) (172.18.0.5, executor 1, partition 0, ANY, 13416 bytes) 
25/12/12 03:21:31 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 31) (172.18.0.5, executor 0, partition 1, ANY, 13416 bytes) 
25/12/12 03:21:31 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 32) (172.18.0.5, executor 1, partition 2, ANY, 13416 bytes) 
25/12/12 03:21:31 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 33) (172.18.0.5, executor 0, partition 3, ANY, 13416 bytes) 
25/12/12 03:21:31 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 34) (172.18.0.5, executor 1, partition 4, ANY, 13416 bytes) 
25/12/12 03:21:31 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 35) (172.18.0.5, executor 0, partition 5, ANY, 13416 bytes) 
25/12/12 03:21:31 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 36) (172.18.0.5, executor 1, partition 6, ANY, 13416 bytes) 
25/12/12 03:21:31 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 37) (172.18.0.5, executor 0, partition 7, ANY, 13540 bytes) 
25/12/12 03:21:31 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 81.7 KiB, free 433.2 MiB)
25/12/12 03:21:31 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 433.1 MiB)
25/12/12 03:21:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:21:31 INFO FileSourceStrategy: Post-Scan Filters: (size(features#189, true) > 0),isnotnull(features#189)
25/12/12 03:21:31 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on spark-master:41121 (size: 25.7 KiB, free: 434.2 MiB)
25/12/12 03:21:31 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[48] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:31 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/12/12 03:21:31 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.5:36293 (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:21:31 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.5:35921 (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:21:31 INFO TorrentBroadcast: Started reading broadcast variable 16 with 1 pieces (estimated total size 4.0 MiB)
25/12/12 03:21:31 INFO TorrentBroadcast: Reading broadcast variable 16 took 3 ms
25/12/12 03:21:32 INFO CodeGenerator: Code generated in 140.974333 ms
25/12/12 03:21:32 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 313.8 KiB, free 432.8 MiB)
25/12/12 03:21:32 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 432.8 MiB)
25/12/12 03:21:32 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 434.1 MiB)
25/12/12 03:21:32 INFO SparkContext: Created broadcast 21 from collect at /app/src/q5.py:175
25/12/12 03:21:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 22990761 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:21:32 INFO DAGScheduler: Registering RDD 60 (collect at /app/src/q5.py:175) as input to shuffle 4
25/12/12 03:21:32 INFO DAGScheduler: Got map stage job 10 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:21:32 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (collect at /app/src/q5.py:175)
25/12/12 03:21:32 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:32 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:32 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[60] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:32 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 124.8 KiB, free 432.7 MiB)
25/12/12 03:21:32 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 42.0 KiB, free 432.6 MiB)
25/12/12 03:21:32 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on spark-master:41121 (size: 42.0 KiB, free: 434.1 MiB)
25/12/12 03:21:32 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[60] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:32 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/12/12 03:21:33 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 38) (172.18.0.5, executor 1, partition 0, ANY, 13404 bytes) 
25/12/12 03:21:33 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 32) in 1899 ms on 172.18.0.5 (executor 1) (1/8)
25/12/12 03:21:33 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 39) (172.18.0.5, executor 0, partition 0, ANY, 13404 bytes) 
25/12/12 03:21:33 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 37) in 1905 ms on 172.18.0.5 (executor 0) (2/8)
25/12/12 03:21:33 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.5:36293 (size: 42.0 KiB, free: 4.6 GiB)
25/12/12 03:21:33 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.5:35921 (size: 25.7 KiB, free: 4.6 GiB)
25/12/12 03:21:33 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 34) in 1949 ms on 172.18.0.5 (executor 1) (3/8)
25/12/12 03:21:33 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 30) in 1952 ms on 172.18.0.5 (executor 1) (4/8)
25/12/12 03:21:33 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 31) in 1990 ms on 172.18.0.5 (executor 0) (5/8)
25/12/12 03:21:33 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 33) in 2058 ms on 172.18.0.5 (executor 0) (6/8)
25/12/12 03:21:33 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 36) in 2100 ms on 172.18.0.5 (executor 1) (7/8)
25/12/12 03:21:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.5:35921 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:21:33 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.5:36293 (size: 5.5 KiB, free: 4.6 GiB)
25/12/12 03:21:34 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.18.0.5:36293 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:21:35 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 35) in 3547 ms on 172.18.0.5 (executor 0) (8/8)
25/12/12 03:21:35 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/12/12 03:21:35 INFO DAGScheduler: ShuffleMapStage 10 (collect at /app/src/q5.py:175) finished in 3.562 s
25/12/12 03:21:35 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:21:35 INFO DAGScheduler: running: Set(ShuffleMapStage 13, ShuffleMapStage 11)
25/12/12 03:21:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 12)
25/12/12 03:21:35 INFO DAGScheduler: failed: Set()
25/12/12 03:21:41 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 39) in 8372 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:21:41 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/12/12 03:21:42 INFO DAGScheduler: ShuffleMapStage 13 (collect at /app/src/q5.py:175) finished in 9.942 s
25/12/12 03:21:42 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:21:42 INFO DAGScheduler: running: Set(ShuffleMapStage 11)
25/12/12 03:21:42 INFO DAGScheduler: waiting: Set(ShuffleMapStage 12)
25/12/12 03:21:42 INFO DAGScheduler: failed: Set()
25/12/12 03:21:45 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 38) in 11749 ms on 172.18.0.5 (executor 1) (1/1)
25/12/12 03:21:45 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/12/12 03:21:45 INFO DAGScheduler: ShuffleMapStage 11 (collect at /app/src/q5.py:175) finished in 13.648 s
25/12/12 03:21:45 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:21:45 INFO DAGScheduler: running: Set()
25/12/12 03:21:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 12)
25/12/12 03:21:45 INFO DAGScheduler: failed: Set()
25/12/12 03:21:45 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[56] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:45 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 120.1 KiB, free 432.5 MiB)
25/12/12 03:21:45 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 43.3 KiB, free 432.5 MiB)
25/12/12 03:21:45 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on spark-master:41121 (size: 43.3 KiB, free: 434.0 MiB)
25/12/12 03:21:45 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:45 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[56] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
25/12/12 03:21:45 INFO TaskSchedulerImpl: Adding task set 12.0 with 12 tasks resource profile 0
25/12/12 03:21:45 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 40) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:45 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 41) (172.18.0.5, executor 1, partition 1, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:45 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 42) (172.18.0.5, executor 0, partition 2, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:45 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 43) (172.18.0.5, executor 1, partition 3, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:45 INFO TaskSetManager: Starting task 4.0 in stage 12.0 (TID 44) (172.18.0.5, executor 0, partition 4, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:45 INFO TaskSetManager: Starting task 5.0 in stage 12.0 (TID 45) (172.18.0.5, executor 1, partition 5, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:45 INFO TaskSetManager: Starting task 6.0 in stage 12.0 (TID 46) (172.18.0.5, executor 0, partition 6, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:45 INFO TaskSetManager: Starting task 7.0 in stage 12.0 (TID 47) (172.18.0.5, executor 1, partition 7, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:45 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.5:35921 (size: 43.3 KiB, free: 4.6 GiB)
25/12/12 03:21:45 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.5:36293 (size: 43.3 KiB, free: 4.6 GiB)
25/12/12 03:21:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.5:35914
25/12/12 03:21:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.5:35914
25/12/12 03:21:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.5:35906
25/12/12 03:21:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.5:35906
25/12/12 03:21:47 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.5:35921 (size: 508.0 B, free: 4.6 GiB)
25/12/12 03:21:47 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.5:36293 (size: 508.0 B, free: 4.6 GiB)
25/12/12 03:21:49 INFO TaskSetManager: Starting task 8.0 in stage 12.0 (TID 48) (172.18.0.5, executor 0, partition 8, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:49 INFO TaskSetManager: Finished task 6.0 in stage 12.0 (TID 46) in 3641 ms on 172.18.0.5 (executor 0) (1/12)
25/12/12 03:21:49 INFO TaskSetManager: Starting task 9.0 in stage 12.0 (TID 49) (172.18.0.5, executor 1, partition 9, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:49 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 43) in 3654 ms on 172.18.0.5 (executor 1) (2/12)
25/12/12 03:21:49 INFO TaskSetManager: Starting task 10.0 in stage 12.0 (TID 50) (172.18.0.5, executor 1, partition 10, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:49 INFO TaskSetManager: Finished task 5.0 in stage 12.0 (TID 45) in 4062 ms on 172.18.0.5 (executor 1) (3/12)
25/12/12 03:21:49 INFO TaskSetManager: Starting task 11.0 in stage 12.0 (TID 51) (172.18.0.5, executor 1, partition 11, NODE_LOCAL, 12876 bytes) 
25/12/12 03:21:49 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 41) in 4210 ms on 172.18.0.5 (executor 1) (4/12)
25/12/12 03:21:49 INFO TaskSetManager: Finished task 4.0 in stage 12.0 (TID 44) in 4450 ms on 172.18.0.5 (executor 0) (5/12)
25/12/12 03:21:49 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 40) in 4569 ms on 172.18.0.5 (executor 0) (6/12)
25/12/12 03:21:50 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 42) in 4680 ms on 172.18.0.5 (executor 0) (7/12)
25/12/12 03:21:50 INFO TaskSetManager: Finished task 7.0 in stage 12.0 (TID 47) in 4755 ms on 172.18.0.5 (executor 1) (8/12)
25/12/12 03:21:50 INFO TaskSetManager: Finished task 9.0 in stage 12.0 (TID 49) in 1556 ms on 172.18.0.5 (executor 1) (9/12)
25/12/12 03:21:50 INFO TaskSetManager: Finished task 10.0 in stage 12.0 (TID 50) in 1201 ms on 172.18.0.5 (executor 1) (10/12)
25/12/12 03:21:50 INFO TaskSetManager: Finished task 8.0 in stage 12.0 (TID 48) in 1696 ms on 172.18.0.5 (executor 0) (11/12)
25/12/12 03:21:50 INFO TaskSetManager: Finished task 11.0 in stage 12.0 (TID 51) in 1155 ms on 172.18.0.5 (executor 1) (12/12)
25/12/12 03:21:50 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/12/12 03:21:50 INFO DAGScheduler: ShuffleMapStage 12 (collect at /app/src/q5.py:175) finished in 5.410 s
25/12/12 03:21:50 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:21:50 INFO DAGScheduler: running: Set()
25/12/12 03:21:50 INFO DAGScheduler: waiting: Set()
25/12/12 03:21:50 INFO DAGScheduler: failed: Set()
25/12/12 03:21:50 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/12/12 03:21:50 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/12/12 03:21:50 INFO CodeGenerator: Code generated in 22.3315 ms
25/12/12 03:21:50 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:21:51 INFO DAGScheduler: Got job 11 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:21:51 INFO DAGScheduler: Final stage: ResultStage 17 (collect at /app/src/q5.py:175)
25/12/12 03:21:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
25/12/12 03:21:51 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:51 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[63] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 67.6 KiB, free 432.4 MiB)
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 432.4 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on spark-master:41121 (size: 29.5 KiB, free: 434.0 MiB)
25/12/12 03:21:51 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[63] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:51 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_22_piece0 on spark-master:41121 in memory (size: 42.0 KiB, free: 434.1 MiB)
25/12/12 03:21:51 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 52) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 12797 bytes) 
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.18.0.5:36293 in memory (size: 42.0 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_23_piece0 on spark-master:41121 in memory (size: 43.3 KiB, free: 434.1 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.18.0.5:36293 in memory (size: 43.3 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.18.0.5:35921 in memory (size: 43.3 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_19_piece0 on spark-master:41121 in memory (size: 16.8 KiB, free: 434.1 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.5:36293 in memory (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.5:35921 in memory (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.5:36293 (size: 29.5 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_20_piece0 on spark-master:41121 in memory (size: 25.7 KiB, free: 434.1 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.5:35921 in memory (size: 25.7 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:35914
25/12/12 03:21:51 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 52) in 152 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:21:51 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
25/12/12 03:21:51 INFO DAGScheduler: ResultStage 17 (collect at /app/src/q5.py:175) finished in 0.203 s
25/12/12 03:21:51 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
25/12/12 03:21:51 INFO DAGScheduler: Job 11 finished: collect at /app/src/q5.py:175, took 0.209182 s
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 432.8 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on spark-master:41121 (size: 5.4 KiB, free: 434.1 MiB)
25/12/12 03:21:51 INFO SparkContext: Created broadcast 25 from collect at /app/src/q5.py:175
25/12/12 03:21:51 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/12/12 03:21:51 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/12/12 03:21:51 INFO CodeGenerator: Code generated in 27.031 ms
25/12/12 03:21:51 INFO DAGScheduler: Registering RDD 66 (collect at /app/src/q5.py:175) as input to shuffle 5
25/12/12 03:21:51 INFO DAGScheduler: Got map stage job 12 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:21:51 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (collect at /app/src/q5.py:175)
25/12/12 03:21:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
25/12/12 03:21:51 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:51 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[66] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 122.3 KiB, free 432.7 MiB)
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 48.7 KiB, free 432.7 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on spark-master:41121 (size: 48.7 KiB, free: 434.1 MiB)
25/12/12 03:21:51 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[66] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:51 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
25/12/12 03:21:51 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 53) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 12786 bytes) 
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.18.0.5:36293 (size: 48.7 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.5:35914
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.5:36293 (size: 5.4 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 53) in 99 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:21:51 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
25/12/12 03:21:51 INFO DAGScheduler: ShuffleMapStage 19 (collect at /app/src/q5.py:175) finished in 0.109 s
25/12/12 03:21:51 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:21:51 INFO DAGScheduler: running: Set()
25/12/12 03:21:51 INFO DAGScheduler: waiting: Set()
25/12/12 03:21:51 INFO DAGScheduler: failed: Set()
25/12/12 03:21:51 INFO CodeGenerator: Code generated in 9.774584 ms
25/12/12 03:21:51 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:21:51 INFO DAGScheduler: Got job 13 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:21:51 INFO DAGScheduler: Final stage: ResultStage 22 (collect at /app/src/q5.py:175)
25/12/12 03:21:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
25/12/12 03:21:51 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:51 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[69] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 24.0 KiB, free 432.7 MiB)
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 432.6 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on spark-master:41121 (size: 9.0 KiB, free: 434.1 MiB)
25/12/12 03:21:51 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[69] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:51 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
25/12/12 03:21:51 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 54) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 12797 bytes) 
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.18.0.5:36293 (size: 9.0 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.5:35914
25/12/12 03:21:51 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 54) in 38 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:21:51 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
25/12/12 03:21:51 INFO DAGScheduler: ResultStage 22 (collect at /app/src/q5.py:175) finished in 0.044 s
25/12/12 03:21:51 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
25/12/12 03:21:51 INFO DAGScheduler: Job 13 finished: collect at /app/src/q5.py:175, took 0.045906 s
Correlation (all areas): -0.2781621187833442
25/12/12 03:21:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:21:51 INFO FileSourceStrategy: Post-Scan Filters: (size(features#189, true) > 0),isnotnull(features#189)
25/12/12 03:21:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Estimated Median Income),IsNotNull(Zip Code)
25/12/12 03:21:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Estimated Median Income#231),isnotnull(Zip Code#229),isnotnull(cast(regexp_replace(Estimated Median Income#231, [$,], , 1) as double))
25/12/12 03:21:51 INFO JoinQueryDetector: Planning spatial join for ST_CONTAINS relationship with swapped left and right shapes
25/12/12 03:21:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(LAT),IsNotNull(LON),Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)),IsNotNull(DATE OCC)
25/12/12 03:21:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(LAT#62),isnotnull(LON#63),NOT (LAT#62 = 0.0),NOT (LON#63 = 0.0),isnotnull(DATE OCC#38),isnotnull(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false))),(year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) >= 2020),(year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) <= 2021),isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )
25/12/12 03:21:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:21:51 INFO FileSourceStrategy: Post-Scan Filters: (size(features#279, true) > 0),isnotnull(features#279)
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 314.0 KiB, free 432.0 MiB)
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 314.0 KiB, free 432.0 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_27_piece0 on spark-master:41121 in memory (size: 9.0 KiB, free: 434.1 MiB)
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 57.4 KiB, free 432.0 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on spark-master:41121 (size: 57.4 KiB, free: 434.0 MiB)
25/12/12 03:21:51 INFO SparkContext: Created broadcast 29 from collect at /app/src/q5.py:175
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 432.0 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 434.0 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.18.0.5:36293 in memory (size: 9.0 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO SparkContext: Created broadcast 28 from collect at /app/src/q5.py:175
25/12/12 03:21:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 118509402 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:21:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_24_piece0 on spark-master:41121 in memory (size: 29.5 KiB, free: 434.0 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.18.0.5:36293 in memory (size: 29.5 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:21:51 INFO DAGScheduler: Got job 14 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:21:51 INFO DAGScheduler: Final stage: ResultStage 23 (collect at /app/src/q5.py:175)
25/12/12 03:21:51 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:51 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:51 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[77] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 313.8 KiB, free 431.7 MiB)
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 19.9 KiB, free 431.7 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.18.0.5:36293 in memory (size: 48.7 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Removed broadcast_26_piece0 on spark-master:41121 in memory (size: 48.7 KiB, free: 434.1 MiB)
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 431.9 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on spark-master:41121 (size: 9.0 KiB, free: 434.0 MiB)
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 431.8 MiB)
25/12/12 03:21:51 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 434.0 MiB)
25/12/12 03:21:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[77] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:21:51 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
25/12/12 03:21:51 INFO SparkContext: Created broadcast 30 from collect at /app/src/q5.py:175
25/12/12 03:21:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 22990761 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:21:51 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 55) (172.18.0.5, executor 0, partition 0, ANY, 13404 bytes) 
25/12/12 03:21:51 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:21:51 INFO DAGScheduler: Got job 15 (collect at /app/src/q5.py:175) with 8 output partitions
25/12/12 03:21:51 INFO DAGScheduler: Final stage: ResultStage 24 (collect at /app/src/q5.py:175)
25/12/12 03:21:51 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:51 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:51 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[82] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.18.0.5:36293 (size: 9.0 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 31.2 KiB, free 431.8 MiB)
25/12/12 03:21:51 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 431.8 MiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on spark-master:41121 (size: 14.5 KiB, free: 434.0 MiB)
25/12/12 03:21:51 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:51 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 24 (MapPartitionsRDD[82] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:21:51 INFO TaskSchedulerImpl: Adding task set 24.0 with 8 tasks resource profile 0
25/12/12 03:21:51 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 56) (172.18.0.5, executor 1, partition 0, ANY, 13427 bytes) 
25/12/12 03:21:51 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 57) (172.18.0.5, executor 0, partition 1, ANY, 13427 bytes) 
25/12/12 03:21:51 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 58) (172.18.0.5, executor 1, partition 2, ANY, 13427 bytes) 
25/12/12 03:21:51 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 59) (172.18.0.5, executor 0, partition 3, ANY, 13427 bytes) 
25/12/12 03:21:51 INFO TaskSetManager: Starting task 4.0 in stage 24.0 (TID 60) (172.18.0.5, executor 1, partition 4, ANY, 13427 bytes) 
25/12/12 03:21:51 INFO TaskSetManager: Starting task 5.0 in stage 24.0 (TID 61) (172.18.0.5, executor 0, partition 5, ANY, 13427 bytes) 
25/12/12 03:21:51 INFO TaskSetManager: Starting task 6.0 in stage 24.0 (TID 62) (172.18.0.5, executor 1, partition 6, ANY, 13427 bytes) 
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.18.0.5:36293 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.18.0.5:35921 (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:21:51 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.18.0.5:36293 (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:21:52 INFO TaskSetManager: Starting task 7.0 in stage 24.0 (TID 63) (172.18.0.5, executor 0, partition 7, ANY, 13551 bytes) 
25/12/12 03:21:52 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 55) in 102 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:21:52 INFO DAGScheduler: ResultStage 23 (collect at /app/src/q5.py:175) finished in 0.126 s
25/12/12 03:21:52 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:52 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
25/12/12 03:21:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
25/12/12 03:21:52 INFO DAGScheduler: Job 14 finished: collect at /app/src/q5.py:175, took 0.132836 s
25/12/12 03:21:52 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 431.8 MiB)
25/12/12 03:21:52 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on spark-master:41121 (size: 5.5 KiB, free: 434.0 MiB)
25/12/12 03:21:52 INFO SparkContext: Created broadcast 33 from collect at /app/src/q5.py:175
25/12/12 03:21:52 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.18.0.5:36293 (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:21:52 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.18.0.5:35921 (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:21:54 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 56) in 3010 ms on 172.18.0.5 (executor 1) (1/8)
25/12/12 03:21:54 INFO TaskSetManager: Finished task 6.0 in stage 24.0 (TID 62) in 3011 ms on 172.18.0.5 (executor 1) (2/8)
25/12/12 03:21:54 INFO TaskSetManager: Finished task 4.0 in stage 24.0 (TID 60) in 3019 ms on 172.18.0.5 (executor 1) (3/8)
25/12/12 03:21:55 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 58) in 3032 ms on 172.18.0.5 (executor 1) (4/8)
25/12/12 03:21:55 INFO TaskSetManager: Finished task 7.0 in stage 24.0 (TID 63) in 3095 ms on 172.18.0.5 (executor 0) (5/8)
25/12/12 03:21:55 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 57) in 3240 ms on 172.18.0.5 (executor 0) (6/8)
25/12/12 03:21:55 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 59) in 3266 ms on 172.18.0.5 (executor 0) (7/8)
25/12/12 03:21:55 INFO TaskSetManager: Finished task 5.0 in stage 24.0 (TID 61) in 3417 ms on 172.18.0.5 (executor 0) (8/8)
25/12/12 03:21:55 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
25/12/12 03:21:55 INFO DAGScheduler: ResultStage 24 (collect at /app/src/q5.py:175) finished in 3.424 s
25/12/12 03:21:55 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
25/12/12 03:21:55 INFO DAGScheduler: Job 15 finished: collect at /app/src/q5.py:175, took 3.431273 s
25/12/12 03:21:55 INFO RangeJoinExec: [SedonaSQL] Number of partitions on the left: 8
25/12/12 03:21:55 INFO RangeJoinExec: [SedonaSQL] Number of partitions on the right: 1
25/12/12 03:21:55 INFO RangeJoinExec: [SedonaSQL] Dominant side count: 407488
25/12/12 03:21:55 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:21:55 INFO DAGScheduler: Got job 16 (collect at /app/src/q5.py:175) with 8 output partitions
25/12/12 03:21:55 INFO DAGScheduler: Final stage: ResultStage 25 (collect at /app/src/q5.py:175)
25/12/12 03:21:55 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:21:55 INFO DAGScheduler: Missing parents: List()
25/12/12 03:21:55 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[85] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:21:55 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 32.1 KiB, free 431.7 MiB)
25/12/12 03:21:55 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 431.7 MiB)
25/12/12 03:21:55 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on spark-master:41121 (size: 15.1 KiB, free: 434.0 MiB)
25/12/12 03:21:55 INFO BlockManagerInfo: Removed broadcast_31_piece0 on spark-master:41121 in memory (size: 9.0 KiB, free: 434.0 MiB)
25/12/12 03:21:55 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1580
25/12/12 03:21:55 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 25 (MapPartitionsRDD[85] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:21:55 INFO TaskSchedulerImpl: Adding task set 25.0 with 8 tasks resource profile 0
25/12/12 03:21:55 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 64) (172.18.0.5, executor 1, partition 0, ANY, 13536 bytes) 
25/12/12 03:21:55 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 65) (172.18.0.5, executor 0, partition 1, ANY, 13536 bytes) 
25/12/12 03:21:55 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 66) (172.18.0.5, executor 1, partition 2, ANY, 13536 bytes) 
25/12/12 03:21:55 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 67) (172.18.0.5, executor 0, partition 3, ANY, 13536 bytes) 
25/12/12 03:21:55 INFO TaskSetManager: Starting task 4.0 in stage 25.0 (TID 68) (172.18.0.5, executor 1, partition 4, ANY, 13536 bytes) 
25/12/12 03:21:55 INFO TaskSetManager: Starting task 5.0 in stage 25.0 (TID 69) (172.18.0.5, executor 0, partition 5, ANY, 13536 bytes) 
25/12/12 03:21:55 INFO TaskSetManager: Starting task 6.0 in stage 25.0 (TID 70) (172.18.0.5, executor 1, partition 6, ANY, 13536 bytes) 
25/12/12 03:21:55 INFO TaskSetManager: Starting task 7.0 in stage 25.0 (TID 71) (172.18.0.5, executor 0, partition 7, ANY, 13660 bytes) 
25/12/12 03:21:55 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.18.0.5:36293 in memory (size: 9.0 KiB, free: 4.6 GiB)
25/12/12 03:21:55 INFO BlockManagerInfo: Removed broadcast_32_piece0 on spark-master:41121 in memory (size: 14.5 KiB, free: 434.0 MiB)
25/12/12 03:21:55 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.18.0.5:36293 in memory (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:21:55 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.18.0.5:35921 in memory (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:21:55 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.18.0.5:36293 (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:21:55 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.18.0.5:35921 (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:21:59 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 65) in 3729 ms on 172.18.0.5 (executor 0) (1/8)
25/12/12 03:21:59 INFO TaskSetManager: Finished task 7.0 in stage 25.0 (TID 71) in 3739 ms on 172.18.0.5 (executor 0) (2/8)
25/12/12 03:21:59 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 67) in 3756 ms on 172.18.0.5 (executor 0) (3/8)
25/12/12 03:21:59 INFO TaskSetManager: Finished task 5.0 in stage 25.0 (TID 69) in 4324 ms on 172.18.0.5 (executor 0) (4/8)
25/12/12 03:21:59 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 66) in 4366 ms on 172.18.0.5 (executor 1) (5/8)
25/12/12 03:21:59 INFO TaskSetManager: Finished task 4.0 in stage 25.0 (TID 68) in 4365 ms on 172.18.0.5 (executor 1) (6/8)
25/12/12 03:21:59 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 64) in 4368 ms on 172.18.0.5 (executor 1) (7/8)
25/12/12 03:21:59 INFO TaskSetManager: Finished task 6.0 in stage 25.0 (TID 70) in 4394 ms on 172.18.0.5 (executor 1) (8/8)
25/12/12 03:21:59 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
25/12/12 03:21:59 INFO DAGScheduler: ResultStage 25 (collect at /app/src/q5.py:175) finished in 4.473 s
25/12/12 03:21:59 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:21:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
25/12/12 03:21:59 INFO DAGScheduler: Job 16 finished: collect at /app/src/q5.py:175, took 4.486247 s
25/12/12 03:21:59 INFO SpatialRDD: Collected 4410 samples
25/12/12 03:21:59 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.
25/12/12 03:21:59 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 720.0 B, free 431.8 MiB)
25/12/12 03:21:59 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 506.0 B, free 431.8 MiB)
25/12/12 03:21:59 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on spark-master:41121 (size: 506.0 B, free: 434.0 MiB)
25/12/12 03:21:59 INFO SparkContext: Created broadcast 35 from collect at /app/src/q5.py:175
25/12/12 03:22:00 INFO DAGScheduler: Registering RDD 86 (collect at /app/src/q5.py:175) as input to shuffle 8
25/12/12 03:22:00 INFO DAGScheduler: Registering RDD 89 (collect at /app/src/q5.py:175) as input to shuffle 7
25/12/12 03:22:00 INFO DAGScheduler: Registering RDD 97 (collect at /app/src/q5.py:175) as input to shuffle 6
25/12/12 03:22:00 INFO DAGScheduler: Got map stage job 17 (collect at /app/src/q5.py:175) with 12 output partitions
25/12/12 03:22:00 INFO DAGScheduler: Final stage: ShuffleMapStage 28 (collect at /app/src/q5.py:175)
25/12/12 03:22:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27, ShuffleMapStage 26)
25/12/12 03:22:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27, ShuffleMapStage 26)
25/12/12 03:22:00 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[86] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:00 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 35.5 KiB, free 431.8 MiB)
25/12/12 03:22:00 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 431.7 MiB)
25/12/12 03:22:00 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on spark-master:41121 (size: 16.8 KiB, free: 434.0 MiB)
25/12/12 03:22:00 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:00 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[86] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:22:00 INFO TaskSchedulerImpl: Adding task set 26.0 with 8 tasks resource profile 0
25/12/12 03:22:00 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[89] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:00 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 72) (172.18.0.5, executor 1, partition 0, ANY, 13416 bytes) 
25/12/12 03:22:00 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 73) (172.18.0.5, executor 0, partition 1, ANY, 13416 bytes) 
25/12/12 03:22:00 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 81.7 KiB, free 431.7 MiB)
25/12/12 03:22:00 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 74) (172.18.0.5, executor 1, partition 2, ANY, 13416 bytes) 
25/12/12 03:22:00 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 75) (172.18.0.5, executor 0, partition 3, ANY, 13416 bytes) 
25/12/12 03:22:00 INFO TaskSetManager: Starting task 4.0 in stage 26.0 (TID 76) (172.18.0.5, executor 1, partition 4, ANY, 13416 bytes) 
25/12/12 03:22:00 INFO TaskSetManager: Starting task 5.0 in stage 26.0 (TID 77) (172.18.0.5, executor 0, partition 5, ANY, 13416 bytes) 
25/12/12 03:22:00 INFO TaskSetManager: Starting task 6.0 in stage 26.0 (TID 78) (172.18.0.5, executor 1, partition 6, ANY, 13416 bytes) 
25/12/12 03:22:00 INFO TaskSetManager: Starting task 7.0 in stage 26.0 (TID 79) (172.18.0.5, executor 0, partition 7, ANY, 13540 bytes) 
25/12/12 03:22:00 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 431.6 MiB)
25/12/12 03:22:00 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on spark-master:41121 (size: 25.7 KiB, free: 433.9 MiB)
25/12/12 03:22:00 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[89] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:00 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
25/12/12 03:22:00 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:22:00 INFO FileSourceStrategy: Post-Scan Filters: (size(features#189, true) > 0),isnotnull(features#189)
25/12/12 03:22:00 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.18.0.5:35921 (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:22:00 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.18.0.5:36293 (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:22:00 INFO TorrentBroadcast: Started reading broadcast variable 33 with 1 pieces (estimated total size 4.0 MiB)
25/12/12 03:22:00 INFO TorrentBroadcast: Reading broadcast variable 33 took 0 ms
25/12/12 03:22:00 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 313.8 KiB, free 431.3 MiB)
25/12/12 03:22:00 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 431.3 MiB)
25/12/12 03:22:00 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 433.9 MiB)
25/12/12 03:22:00 INFO SparkContext: Created broadcast 38 from collect at /app/src/q5.py:175
25/12/12 03:22:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 22990761 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:22:00 INFO DAGScheduler: Registering RDD 101 (collect at /app/src/q5.py:175) as input to shuffle 9
25/12/12 03:22:00 INFO DAGScheduler: Got map stage job 18 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:22:00 INFO DAGScheduler: Final stage: ShuffleMapStage 29 (collect at /app/src/q5.py:175)
25/12/12 03:22:00 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:22:00 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:00 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[101] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:00 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 125.1 KiB, free 431.2 MiB)
25/12/12 03:22:00 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 42.2 KiB, free 431.1 MiB)
25/12/12 03:22:00 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on spark-master:41121 (size: 42.2 KiB, free: 433.8 MiB)
25/12/12 03:22:00 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[101] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:00 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
25/12/12 03:22:03 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 80) (172.18.0.5, executor 0, partition 0, ANY, 13404 bytes) 
25/12/12 03:22:03 INFO TaskSetManager: Finished task 7.0 in stage 26.0 (TID 79) in 3868 ms on 172.18.0.5 (executor 0) (1/8)
25/12/12 03:22:04 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 81) (172.18.0.5, executor 0, partition 0, ANY, 13404 bytes) 
25/12/12 03:22:04 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 75) in 4025 ms on 172.18.0.5 (executor 0) (2/8)
25/12/12 03:22:04 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.18.0.5:36293 (size: 25.7 KiB, free: 4.6 GiB)
25/12/12 03:22:04 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.18.0.5:36293 (size: 42.2 KiB, free: 4.6 GiB)
25/12/12 03:22:04 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.18.0.5:36293 (size: 5.5 KiB, free: 4.6 GiB)
25/12/12 03:22:04 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 73) in 4155 ms on 172.18.0.5 (executor 0) (3/8)
25/12/12 03:22:04 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.18.0.5:36293 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:22:04 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.18.0.5:36293 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:22:04 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 72) in 4335 ms on 172.18.0.5 (executor 1) (4/8)
25/12/12 03:22:04 INFO TaskSetManager: Finished task 4.0 in stage 26.0 (TID 76) in 4337 ms on 172.18.0.5 (executor 1) (5/8)
25/12/12 03:22:04 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 74) in 4373 ms on 172.18.0.5 (executor 1) (6/8)
25/12/12 03:22:04 INFO TaskSetManager: Finished task 6.0 in stage 26.0 (TID 78) in 4473 ms on 172.18.0.5 (executor 1) (7/8)
25/12/12 03:22:05 INFO TaskSetManager: Finished task 5.0 in stage 26.0 (TID 77) in 5696 ms on 172.18.0.5 (executor 0) (8/8)
25/12/12 03:22:05 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
25/12/12 03:22:05 INFO DAGScheduler: ShuffleMapStage 26 (collect at /app/src/q5.py:175) finished in 5.731 s
25/12/12 03:22:05 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:22:05 INFO DAGScheduler: running: Set(ShuffleMapStage 27, ShuffleMapStage 29)
25/12/12 03:22:05 INFO DAGScheduler: waiting: Set(ShuffleMapStage 28)
25/12/12 03:22:05 INFO DAGScheduler: failed: Set()
25/12/12 03:22:12 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 81) in 8149 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:22:12 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
25/12/12 03:22:12 INFO DAGScheduler: ShuffleMapStage 29 (collect at /app/src/q5.py:175) finished in 11.948 s
25/12/12 03:22:12 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:22:12 INFO DAGScheduler: running: Set(ShuffleMapStage 27)
25/12/12 03:22:12 INFO DAGScheduler: waiting: Set(ShuffleMapStage 28)
25/12/12 03:22:12 INFO DAGScheduler: failed: Set()
25/12/12 03:22:15 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 80) in 12032 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:22:15 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
25/12/12 03:22:15 INFO DAGScheduler: ShuffleMapStage 27 (collect at /app/src/q5.py:175) finished in 15.876 s
25/12/12 03:22:15 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:22:15 INFO DAGScheduler: running: Set()
25/12/12 03:22:15 INFO DAGScheduler: waiting: Set(ShuffleMapStage 28)
25/12/12 03:22:15 INFO DAGScheduler: failed: Set()
25/12/12 03:22:15 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[97] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:15 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 120.1 KiB, free 431.0 MiB)
25/12/12 03:22:15 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 43.4 KiB, free 431.0 MiB)
25/12/12 03:22:15 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on spark-master:41121 (size: 43.4 KiB, free: 433.8 MiB)
25/12/12 03:22:15 INFO BlockManagerInfo: Removed broadcast_39_piece0 on spark-master:41121 in memory (size: 42.2 KiB, free: 433.8 MiB)
25/12/12 03:22:15 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:16 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[97] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
25/12/12 03:22:16 INFO TaskSchedulerImpl: Adding task set 28.0 with 12 tasks resource profile 0
25/12/12 03:22:16 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 82) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:16 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.18.0.5:36293 in memory (size: 42.2 KiB, free: 4.6 GiB)
25/12/12 03:22:16 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 83) (172.18.0.5, executor 1, partition 1, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:16 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 84) (172.18.0.5, executor 0, partition 2, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:16 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 85) (172.18.0.5, executor 1, partition 3, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:16 INFO TaskSetManager: Starting task 4.0 in stage 28.0 (TID 86) (172.18.0.5, executor 0, partition 4, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:16 INFO TaskSetManager: Starting task 5.0 in stage 28.0 (TID 87) (172.18.0.5, executor 1, partition 5, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:16 INFO TaskSetManager: Starting task 6.0 in stage 28.0 (TID 88) (172.18.0.5, executor 0, partition 6, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:16 INFO TaskSetManager: Starting task 7.0 in stage 28.0 (TID 89) (172.18.0.5, executor 1, partition 7, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:16 INFO BlockManagerInfo: Removed broadcast_36_piece0 on spark-master:41121 in memory (size: 16.8 KiB, free: 433.9 MiB)
25/12/12 03:22:16 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.18.0.5:36293 in memory (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:22:16 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.18.0.5:35921 in memory (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:22:16 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.18.0.5:36293 (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:22:16 INFO BlockManagerInfo: Removed broadcast_34_piece0 on spark-master:41121 in memory (size: 15.1 KiB, free: 433.9 MiB)
25/12/12 03:22:16 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.18.0.5:35921 in memory (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:22:16 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.18.0.5:36293 in memory (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:22:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.18.0.5:35914
25/12/12 03:22:16 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.18.0.5:35921 (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:22:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.18.0.5:35914
25/12/12 03:22:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.18.0.5:35906
25/12/12 03:22:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.18.0.5:35906
25/12/12 03:22:16 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.18.0.5:36293 (size: 506.0 B, free: 4.6 GiB)
25/12/12 03:22:16 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.18.0.5:35921 (size: 506.0 B, free: 4.6 GiB)
25/12/12 03:22:17 INFO TaskSetManager: Starting task 8.0 in stage 28.0 (TID 90) (172.18.0.5, executor 1, partition 8, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:17 INFO TaskSetManager: Finished task 5.0 in stage 28.0 (TID 87) in 1000 ms on 172.18.0.5 (executor 1) (1/12)
25/12/12 03:22:17 INFO TaskSetManager: Starting task 9.0 in stage 28.0 (TID 91) (172.18.0.5, executor 1, partition 9, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:17 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 85) in 1041 ms on 172.18.0.5 (executor 1) (2/12)
25/12/12 03:22:17 INFO TaskSetManager: Starting task 10.0 in stage 28.0 (TID 92) (172.18.0.5, executor 0, partition 10, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:17 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 84) in 1271 ms on 172.18.0.5 (executor 0) (3/12)
25/12/12 03:22:17 INFO TaskSetManager: Starting task 11.0 in stage 28.0 (TID 93) (172.18.0.5, executor 0, partition 11, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:17 INFO TaskSetManager: Finished task 4.0 in stage 28.0 (TID 86) in 1312 ms on 172.18.0.5 (executor 0) (4/12)
25/12/12 03:22:17 INFO TaskSetManager: Finished task 6.0 in stage 28.0 (TID 88) in 1584 ms on 172.18.0.5 (executor 0) (5/12)
25/12/12 03:22:17 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 82) in 1693 ms on 172.18.0.5 (executor 0) (6/12)
25/12/12 03:22:17 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 83) in 1744 ms on 172.18.0.5 (executor 1) (7/12)
25/12/12 03:22:17 INFO TaskSetManager: Finished task 7.0 in stage 28.0 (TID 89) in 1821 ms on 172.18.0.5 (executor 1) (8/12)
25/12/12 03:22:17 INFO TaskSetManager: Finished task 9.0 in stage 28.0 (TID 91) in 926 ms on 172.18.0.5 (executor 1) (9/12)
25/12/12 03:22:17 INFO TaskSetManager: Finished task 8.0 in stage 28.0 (TID 90) in 976 ms on 172.18.0.5 (executor 1) (10/12)
25/12/12 03:22:18 INFO TaskSetManager: Finished task 10.0 in stage 28.0 (TID 92) in 1252 ms on 172.18.0.5 (executor 0) (11/12)
25/12/12 03:22:18 INFO TaskSetManager: Finished task 11.0 in stage 28.0 (TID 93) in 1267 ms on 172.18.0.5 (executor 0) (12/12)
25/12/12 03:22:18 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
25/12/12 03:22:18 INFO DAGScheduler: ShuffleMapStage 28 (collect at /app/src/q5.py:175) finished in 2.677 s
25/12/12 03:22:18 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:22:18 INFO DAGScheduler: running: Set()
25/12/12 03:22:18 INFO DAGScheduler: waiting: Set()
25/12/12 03:22:18 INFO DAGScheduler: failed: Set()
25/12/12 03:22:18 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/12/12 03:22:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/12/12 03:22:18 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:22:18 INFO DAGScheduler: Got job 19 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:22:18 INFO DAGScheduler: Final stage: ResultStage 33 (collect at /app/src/q5.py:175)
25/12/12 03:22:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
25/12/12 03:22:18 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:18 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[104] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:18 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 67.6 KiB, free 431.2 MiB)
25/12/12 03:22:18 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 431.1 MiB)
25/12/12 03:22:18 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on spark-master:41121 (size: 29.5 KiB, free: 433.8 MiB)
25/12/12 03:22:18 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[104] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:18 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
25/12/12 03:22:18 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 94) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 12797 bytes) 
25/12/12 03:22:18 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.18.0.5:36293 (size: 29.5 KiB, free: 4.6 GiB)
25/12/12 03:22:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.18.0.5:35914
25/12/12 03:22:18 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 94) in 28 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:22:18 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
25/12/12 03:22:18 INFO DAGScheduler: ResultStage 33 (collect at /app/src/q5.py:175) finished in 0.041 s
25/12/12 03:22:18 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:22:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
25/12/12 03:22:18 INFO DAGScheduler: Job 19 finished: collect at /app/src/q5.py:175, took 0.048452 s
25/12/12 03:22:18 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 431.1 MiB)
25/12/12 03:22:18 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on spark-master:41121 (size: 5.4 KiB, free: 433.8 MiB)
25/12/12 03:22:18 INFO SparkContext: Created broadcast 42 from collect at /app/src/q5.py:175
25/12/12 03:22:18 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/12/12 03:22:18 INFO CodeGenerator: Code generated in 26.215625 ms
25/12/12 03:22:18 INFO CodeGenerator: Code generated in 20.355958 ms
25/12/12 03:22:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/12/12 03:22:18 INFO CodeGenerator: Code generated in 13.142 ms
25/12/12 03:22:18 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:22:18 INFO DAGScheduler: Got job 20 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:22:18 INFO DAGScheduler: Final stage: ResultStage 35 (collect at /app/src/q5.py:175)
25/12/12 03:22:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
25/12/12 03:22:18 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:18 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[109] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:18 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 128.6 KiB, free 431.0 MiB)
25/12/12 03:22:18 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 430.9 MiB)
25/12/12 03:22:18 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on spark-master:41121 (size: 50.3 KiB, free: 433.8 MiB)
25/12/12 03:22:18 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[109] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:18 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
25/12/12 03:22:18 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 95) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 12797 bytes) 
25/12/12 03:22:18 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.18.0.5:36293 (size: 50.3 KiB, free: 4.6 GiB)
25/12/12 03:22:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.18.0.5:35914
25/12/12 03:22:18 INFO BlockManagerInfo: Removed broadcast_41_piece0 on spark-master:41121 in memory (size: 29.5 KiB, free: 433.8 MiB)
25/12/12 03:22:18 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.18.0.5:36293 in memory (size: 29.5 KiB, free: 4.6 GiB)
25/12/12 03:22:18 INFO BlockManagerInfo: Removed broadcast_37_piece0 on spark-master:41121 in memory (size: 25.7 KiB, free: 433.8 MiB)
25/12/12 03:22:18 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.18.0.5:36293 in memory (size: 25.7 KiB, free: 4.6 GiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Removed broadcast_40_piece0 on spark-master:41121 in memory (size: 43.4 KiB, free: 433.9 MiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.18.0.5:36293 in memory (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.18.0.5:35921 in memory (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.18.0.5:36293 (size: 5.4 KiB, free: 4.6 GiB)
25/12/12 03:22:19 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 95) in 181 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:22:19 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
25/12/12 03:22:19 INFO DAGScheduler: ResultStage 35 (collect at /app/src/q5.py:175) finished in 0.192 s
25/12/12 03:22:19 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:22:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
25/12/12 03:22:19 INFO DAGScheduler: Job 20 finished: collect at /app/src/q5.py:175, took 0.195291 s
Correlation (top 10 richest areas):   0.12177082436874123
25/12/12 03:22:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:22:19 INFO FileSourceStrategy: Post-Scan Filters: (size(features#189, true) > 0),isnotnull(features#189)
25/12/12 03:22:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Estimated Median Income),IsNotNull(Zip Code)
25/12/12 03:22:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Estimated Median Income#231),isnotnull(Zip Code#229),isnotnull(cast(regexp_replace(Estimated Median Income#231, [$,], , 1) as double))
25/12/12 03:22:19 INFO JoinQueryDetector: Planning spatial join for ST_CONTAINS relationship with swapped left and right shapes
25/12/12 03:22:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(LAT),IsNotNull(LON),Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)),IsNotNull(DATE OCC)
25/12/12 03:22:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(LAT#62),isnotnull(LON#63),NOT (LAT#62 = 0.0),NOT (LON#63 = 0.0),isnotnull(DATE OCC#38),isnotnull(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false))),(year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) >= 2020),(year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) <= 2021),isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )
25/12/12 03:22:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:22:19 INFO FileSourceStrategy: Post-Scan Filters: (size(features#279, true) > 0),isnotnull(features#279)
25/12/12 03:22:19 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 314.0 KiB, free 431.0 MiB)
25/12/12 03:22:19 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 314.0 KiB, free 430.7 MiB)
25/12/12 03:22:19 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 57.4 KiB, free 430.6 MiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on spark-master:41121 (size: 57.4 KiB, free: 433.8 MiB)
25/12/12 03:22:19 INFO SparkContext: Created broadcast 45 from collect at /app/src/q5.py:175
25/12/12 03:22:19 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 430.6 MiB)
25/12/12 03:22:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 118509402 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 433.8 MiB)
25/12/12 03:22:19 INFO SparkContext: Created broadcast 44 from collect at /app/src/q5.py:175
25/12/12 03:22:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:22:19 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:22:19 INFO DAGScheduler: Got job 21 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:22:19 INFO DAGScheduler: Final stage: ResultStage 36 (collect at /app/src/q5.py:175)
25/12/12 03:22:19 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:22:19 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:19 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[117] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:19 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 19.9 KiB, free 430.6 MiB)
25/12/12 03:22:19 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 430.5 MiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on spark-master:41121 (size: 9.0 KiB, free: 433.8 MiB)
25/12/12 03:22:19 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[117] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:19 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
25/12/12 03:22:19 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 96) (172.18.0.5, executor 0, partition 0, ANY, 13404 bytes) 
25/12/12 03:22:19 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 313.8 KiB, free 430.2 MiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.18.0.5:36293 (size: 9.0 KiB, free: 4.6 GiB)
25/12/12 03:22:19 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 430.2 MiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 433.7 MiB)
25/12/12 03:22:19 INFO SparkContext: Created broadcast 47 from collect at /app/src/q5.py:175
25/12/12 03:22:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 22990761 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.18.0.5:36293 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:22:19 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:22:19 INFO DAGScheduler: Got job 22 (collect at /app/src/q5.py:175) with 8 output partitions
25/12/12 03:22:19 INFO DAGScheduler: Final stage: ResultStage 37 (collect at /app/src/q5.py:175)
25/12/12 03:22:19 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:22:19 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:19 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[122] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:19 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 31.2 KiB, free 430.2 MiB)
25/12/12 03:22:19 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 430.1 MiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on spark-master:41121 (size: 14.5 KiB, free: 433.7 MiB)
25/12/12 03:22:19 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:19 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 37 (MapPartitionsRDD[122] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:22:19 INFO TaskSchedulerImpl: Adding task set 37.0 with 8 tasks resource profile 0
25/12/12 03:22:19 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 97) (172.18.0.5, executor 1, partition 0, ANY, 13427 bytes) 
25/12/12 03:22:19 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 98) (172.18.0.5, executor 0, partition 1, ANY, 13427 bytes) 
25/12/12 03:22:19 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 99) (172.18.0.5, executor 1, partition 2, ANY, 13427 bytes) 
25/12/12 03:22:19 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 100) (172.18.0.5, executor 0, partition 3, ANY, 13427 bytes) 
25/12/12 03:22:19 INFO TaskSetManager: Starting task 4.0 in stage 37.0 (TID 101) (172.18.0.5, executor 1, partition 4, ANY, 13427 bytes) 
25/12/12 03:22:19 INFO TaskSetManager: Starting task 5.0 in stage 37.0 (TID 102) (172.18.0.5, executor 0, partition 5, ANY, 13427 bytes) 
25/12/12 03:22:19 INFO TaskSetManager: Starting task 6.0 in stage 37.0 (TID 103) (172.18.0.5, executor 1, partition 6, ANY, 13427 bytes) 
25/12/12 03:22:19 INFO TaskSetManager: Starting task 7.0 in stage 37.0 (TID 104) (172.18.0.5, executor 0, partition 7, ANY, 13551 bytes) 
25/12/12 03:22:19 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 96) in 65 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:22:19 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
25/12/12 03:22:19 INFO DAGScheduler: ResultStage 36 (collect at /app/src/q5.py:175) finished in 0.069 s
25/12/12 03:22:19 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:22:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
25/12/12 03:22:19 INFO DAGScheduler: Job 21 finished: collect at /app/src/q5.py:175, took 0.071708 s
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.18.0.5:35921 (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.18.0.5:36293 (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Removed broadcast_43_piece0 on spark-master:41121 in memory (size: 50.3 KiB, free: 433.7 MiB)
25/12/12 03:22:19 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 430.3 MiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on spark-master:41121 (size: 5.5 KiB, free: 433.7 MiB)
25/12/12 03:22:19 INFO SparkContext: Created broadcast 49 from collect at /app/src/q5.py:175
25/12/12 03:22:19 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.18.0.5:36293 in memory (size: 50.3 KiB, free: 4.6 GiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Removed broadcast_46_piece0 on spark-master:41121 in memory (size: 9.0 KiB, free: 433.7 MiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.18.0.5:36293 in memory (size: 9.0 KiB, free: 4.6 GiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.18.0.5:35921 (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:22:19 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.18.0.5:36293 (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:22:22 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 98) in 2849 ms on 172.18.0.5 (executor 0) (1/8)
25/12/12 03:22:22 INFO TaskSetManager: Finished task 7.0 in stage 37.0 (TID 104) in 2832 ms on 172.18.0.5 (executor 0) (2/8)
25/12/12 03:22:22 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 100) in 2952 ms on 172.18.0.5 (executor 0) (3/8)
25/12/12 03:22:22 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 97) in 3333 ms on 172.18.0.5 (executor 1) (4/8)
25/12/12 03:22:22 INFO TaskSetManager: Finished task 4.0 in stage 37.0 (TID 101) in 3331 ms on 172.18.0.5 (executor 1) (5/8)
25/12/12 03:22:22 INFO TaskSetManager: Finished task 5.0 in stage 37.0 (TID 102) in 3340 ms on 172.18.0.5 (executor 0) (6/8)
25/12/12 03:22:22 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 99) in 3396 ms on 172.18.0.5 (executor 1) (7/8)
25/12/12 03:22:22 INFO TaskSetManager: Finished task 6.0 in stage 37.0 (TID 103) in 3418 ms on 172.18.0.5 (executor 1) (8/8)
25/12/12 03:22:22 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
25/12/12 03:22:22 INFO DAGScheduler: ResultStage 37 (collect at /app/src/q5.py:175) finished in 3.426 s
25/12/12 03:22:22 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:22:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
25/12/12 03:22:22 INFO DAGScheduler: Job 22 finished: collect at /app/src/q5.py:175, took 3.436329 s
25/12/12 03:22:22 INFO RangeJoinExec: [SedonaSQL] Number of partitions on the left: 8
25/12/12 03:22:22 INFO RangeJoinExec: [SedonaSQL] Number of partitions on the right: 1
25/12/12 03:22:22 INFO RangeJoinExec: [SedonaSQL] Dominant side count: 407488
25/12/12 03:22:22 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:22:22 INFO DAGScheduler: Got job 23 (collect at /app/src/q5.py:175) with 8 output partitions
25/12/12 03:22:22 INFO DAGScheduler: Final stage: ResultStage 38 (collect at /app/src/q5.py:175)
25/12/12 03:22:22 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:22:22 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:22 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[125] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:22 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 32.1 KiB, free 430.3 MiB)
25/12/12 03:22:22 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 430.3 MiB)
25/12/12 03:22:22 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on spark-master:41121 (size: 15.1 KiB, free: 433.7 MiB)
25/12/12 03:22:22 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:22 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 38 (MapPartitionsRDD[125] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:22:22 INFO TaskSchedulerImpl: Adding task set 38.0 with 8 tasks resource profile 0
25/12/12 03:22:22 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 105) (172.18.0.5, executor 0, partition 0, ANY, 13536 bytes) 
25/12/12 03:22:22 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 106) (172.18.0.5, executor 1, partition 1, ANY, 13536 bytes) 
25/12/12 03:22:22 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 107) (172.18.0.5, executor 0, partition 2, ANY, 13536 bytes) 
25/12/12 03:22:22 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 108) (172.18.0.5, executor 1, partition 3, ANY, 13536 bytes) 
25/12/12 03:22:22 INFO TaskSetManager: Starting task 4.0 in stage 38.0 (TID 109) (172.18.0.5, executor 0, partition 4, ANY, 13536 bytes) 
25/12/12 03:22:22 INFO TaskSetManager: Starting task 5.0 in stage 38.0 (TID 110) (172.18.0.5, executor 1, partition 5, ANY, 13536 bytes) 
25/12/12 03:22:22 INFO TaskSetManager: Starting task 6.0 in stage 38.0 (TID 111) (172.18.0.5, executor 0, partition 6, ANY, 13536 bytes) 
25/12/12 03:22:22 INFO TaskSetManager: Starting task 7.0 in stage 38.0 (TID 112) (172.18.0.5, executor 1, partition 7, ANY, 13660 bytes) 
25/12/12 03:22:22 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.18.0.5:35921 (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:22:22 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.18.0.5:36293 (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:22:26 INFO TaskSetManager: Finished task 7.0 in stage 38.0 (TID 112) in 3827 ms on 172.18.0.5 (executor 1) (1/8)
25/12/12 03:22:26 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 106) in 3931 ms on 172.18.0.5 (executor 1) (2/8)
25/12/12 03:22:26 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 108) in 3978 ms on 172.18.0.5 (executor 1) (3/8)
25/12/12 03:22:27 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 107) in 4261 ms on 172.18.0.5 (executor 0) (4/8)
25/12/12 03:22:27 INFO TaskSetManager: Finished task 4.0 in stage 38.0 (TID 109) in 4260 ms on 172.18.0.5 (executor 0) (5/8)
25/12/12 03:22:27 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 105) in 4263 ms on 172.18.0.5 (executor 0) (6/8)
25/12/12 03:22:27 INFO TaskSetManager: Finished task 6.0 in stage 38.0 (TID 111) in 4261 ms on 172.18.0.5 (executor 0) (7/8)
25/12/12 03:22:27 INFO TaskSetManager: Finished task 5.0 in stage 38.0 (TID 110) in 4639 ms on 172.18.0.5 (executor 1) (8/8)
25/12/12 03:22:27 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
25/12/12 03:22:27 INFO DAGScheduler: ResultStage 38 (collect at /app/src/q5.py:175) finished in 4.661 s
25/12/12 03:22:27 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:22:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
25/12/12 03:22:27 INFO DAGScheduler: Job 23 finished: collect at /app/src/q5.py:175, took 4.675769 s
25/12/12 03:22:27 INFO SpatialRDD: Collected 4405 samples
25/12/12 03:22:27 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.
25/12/12 03:22:27 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 720.0 B, free 430.3 MiB)
25/12/12 03:22:27 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 508.0 B, free 430.3 MiB)
25/12/12 03:22:27 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on spark-master:41121 (size: 508.0 B, free: 433.7 MiB)
25/12/12 03:22:27 INFO SparkContext: Created broadcast 51 from collect at /app/src/q5.py:175
25/12/12 03:22:27 INFO DAGScheduler: Registering RDD 126 (collect at /app/src/q5.py:175) as input to shuffle 12
25/12/12 03:22:27 INFO DAGScheduler: Registering RDD 129 (collect at /app/src/q5.py:175) as input to shuffle 11
25/12/12 03:22:27 INFO DAGScheduler: Registering RDD 137 (collect at /app/src/q5.py:175) as input to shuffle 10
25/12/12 03:22:27 INFO DAGScheduler: Got map stage job 24 (collect at /app/src/q5.py:175) with 12 output partitions
25/12/12 03:22:27 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (collect at /app/src/q5.py:175)
25/12/12 03:22:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39, ShuffleMapStage 40)
25/12/12 03:22:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39, ShuffleMapStage 40)
25/12/12 03:22:27 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[126] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:27 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 35.5 KiB, free 430.3 MiB)
25/12/12 03:22:27 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 430.2 MiB)
25/12/12 03:22:27 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on spark-master:41121 (size: 16.8 KiB, free: 433.7 MiB)
25/12/12 03:22:27 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:27 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[126] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:22:27 INFO TaskSchedulerImpl: Adding task set 39.0 with 8 tasks resource profile 0
25/12/12 03:22:27 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[129] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:27 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 113) (172.18.0.5, executor 1, partition 0, ANY, 13416 bytes) 
25/12/12 03:22:27 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 114) (172.18.0.5, executor 0, partition 1, ANY, 13416 bytes) 
25/12/12 03:22:27 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 115) (172.18.0.5, executor 1, partition 2, ANY, 13416 bytes) 
25/12/12 03:22:27 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 116) (172.18.0.5, executor 0, partition 3, ANY, 13416 bytes) 
25/12/12 03:22:27 INFO TaskSetManager: Starting task 4.0 in stage 39.0 (TID 117) (172.18.0.5, executor 1, partition 4, ANY, 13416 bytes) 
25/12/12 03:22:27 INFO TaskSetManager: Starting task 5.0 in stage 39.0 (TID 118) (172.18.0.5, executor 0, partition 5, ANY, 13416 bytes) 
25/12/12 03:22:27 INFO TaskSetManager: Starting task 6.0 in stage 39.0 (TID 119) (172.18.0.5, executor 1, partition 6, ANY, 13416 bytes) 
25/12/12 03:22:27 INFO TaskSetManager: Starting task 7.0 in stage 39.0 (TID 120) (172.18.0.5, executor 0, partition 7, ANY, 13540 bytes) 
25/12/12 03:22:27 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 81.7 KiB, free 430.2 MiB)
25/12/12 03:22:27 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 430.1 MiB)
25/12/12 03:22:27 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on spark-master:41121 (size: 25.7 KiB, free: 433.7 MiB)
25/12/12 03:22:27 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[129] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:27 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
25/12/12 03:22:27 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:22:27 INFO FileSourceStrategy: Post-Scan Filters: (size(features#189, true) > 0),isnotnull(features#189)
25/12/12 03:22:27 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.18.0.5:35921 (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:22:27 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.18.0.5:36293 (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:22:27 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 313.8 KiB, free 429.8 MiB)
25/12/12 03:22:27 INFO BlockManagerInfo: Removed broadcast_50_piece0 on spark-master:41121 in memory (size: 15.1 KiB, free: 433.7 MiB)
25/12/12 03:22:27 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 429.8 MiB)
25/12/12 03:22:27 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.18.0.5:35921 in memory (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:22:27 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.18.0.5:36293 in memory (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:22:27 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 433.6 MiB)
25/12/12 03:22:27 INFO SparkContext: Created broadcast 54 from collect at /app/src/q5.py:175
25/12/12 03:22:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 22990761 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:22:27 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.18.0.5:36293 in memory (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:22:27 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.18.0.5:35921 in memory (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:22:27 INFO BlockManagerInfo: Removed broadcast_48_piece0 on spark-master:41121 in memory (size: 14.5 KiB, free: 433.7 MiB)
25/12/12 03:22:27 INFO DAGScheduler: Registering RDD 141 (collect at /app/src/q5.py:175) as input to shuffle 13
25/12/12 03:22:27 INFO DAGScheduler: Got map stage job 25 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:22:27 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (collect at /app/src/q5.py:175)
25/12/12 03:22:27 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:22:27 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:27 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[141] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:27 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 125.1 KiB, free 429.7 MiB)
25/12/12 03:22:27 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 42.2 KiB, free 429.7 MiB)
25/12/12 03:22:27 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on spark-master:41121 (size: 42.2 KiB, free: 433.6 MiB)
25/12/12 03:22:27 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[141] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:27 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
25/12/12 03:22:31 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 121) (172.18.0.5, executor 1, partition 0, ANY, 13404 bytes) 
25/12/12 03:22:31 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 113) in 4299 ms on 172.18.0.5 (executor 1) (1/8)
25/12/12 03:22:31 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 122) (172.18.0.5, executor 1, partition 0, ANY, 13404 bytes) 
25/12/12 03:22:31 INFO TaskSetManager: Finished task 4.0 in stage 39.0 (TID 117) in 4309 ms on 172.18.0.5 (executor 1) (2/8)
25/12/12 03:22:31 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 115) in 4315 ms on 172.18.0.5 (executor 1) (3/8)
25/12/12 03:22:32 INFO TaskSetManager: Finished task 6.0 in stage 39.0 (TID 119) in 4374 ms on 172.18.0.5 (executor 1) (4/8)
25/12/12 03:22:32 INFO TaskSetManager: Finished task 7.0 in stage 39.0 (TID 120) in 4395 ms on 172.18.0.5 (executor 0) (5/8)
25/12/12 03:22:32 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.18.0.5:35921 (size: 25.7 KiB, free: 4.6 GiB)
25/12/12 03:22:32 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.18.0.5:35921 (size: 42.2 KiB, free: 4.6 GiB)
25/12/12 03:22:32 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.18.0.5:35921 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:22:32 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 114) in 4580 ms on 172.18.0.5 (executor 0) (6/8)
25/12/12 03:22:32 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 116) in 4617 ms on 172.18.0.5 (executor 0) (7/8)
25/12/12 03:22:32 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.18.0.5:35921 (size: 5.5 KiB, free: 4.6 GiB)
25/12/12 03:22:32 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.18.0.5:35921 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:22:34 INFO TaskSetManager: Finished task 5.0 in stage 39.0 (TID 118) in 7031 ms on 172.18.0.5 (executor 0) (8/8)
25/12/12 03:22:34 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
25/12/12 03:22:34 INFO DAGScheduler: ShuffleMapStage 39 (collect at /app/src/q5.py:175) finished in 7.059 s
25/12/12 03:22:34 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:22:34 INFO DAGScheduler: running: Set(ShuffleMapStage 42, ShuffleMapStage 40)
25/12/12 03:22:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 41)
25/12/12 03:22:34 INFO DAGScheduler: failed: Set()
25/12/12 03:22:41 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 122) in 9719 ms on 172.18.0.5 (executor 1) (1/1)
25/12/12 03:22:41 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
25/12/12 03:22:41 INFO DAGScheduler: ShuffleMapStage 42 (collect at /app/src/q5.py:175) finished in 13.796 s
25/12/12 03:22:41 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:22:41 INFO DAGScheduler: running: Set(ShuffleMapStage 40)
25/12/12 03:22:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 41)
25/12/12 03:22:41 INFO DAGScheduler: failed: Set()
25/12/12 03:22:45 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 121) in 13709 ms on 172.18.0.5 (executor 1) (1/1)
25/12/12 03:22:45 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
25/12/12 03:22:45 INFO DAGScheduler: ShuffleMapStage 40 (collect at /app/src/q5.py:175) finished in 17.988 s
25/12/12 03:22:45 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:22:45 INFO DAGScheduler: running: Set()
25/12/12 03:22:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 41)
25/12/12 03:22:45 INFO DAGScheduler: failed: Set()
25/12/12 03:22:45 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[137] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:45 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 120.1 KiB, free 429.6 MiB)
25/12/12 03:22:45 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 43.4 KiB, free 429.5 MiB)
25/12/12 03:22:45 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on spark-master:41121 (size: 43.4 KiB, free: 433.6 MiB)
25/12/12 03:22:45 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:45 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[137] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
25/12/12 03:22:45 INFO TaskSchedulerImpl: Adding task set 41.0 with 12 tasks resource profile 0
25/12/12 03:22:45 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 123) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:45 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 124) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:45 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 125) (172.18.0.5, executor 1, partition 2, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:45 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 126) (172.18.0.5, executor 0, partition 3, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:45 INFO TaskSetManager: Starting task 4.0 in stage 41.0 (TID 127) (172.18.0.5, executor 1, partition 4, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:45 INFO TaskSetManager: Starting task 5.0 in stage 41.0 (TID 128) (172.18.0.5, executor 0, partition 5, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:45 INFO TaskSetManager: Starting task 6.0 in stage 41.0 (TID 129) (172.18.0.5, executor 1, partition 6, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:45 INFO TaskSetManager: Starting task 7.0 in stage 41.0 (TID 130) (172.18.0.5, executor 0, partition 7, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:45 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.18.0.5:35921 (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:22:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.18.0.5:35906
25/12/12 03:22:45 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.18.0.5:36293 (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:22:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.18.0.5:35906
25/12/12 03:22:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.18.0.5:35914
25/12/12 03:22:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.18.0.5:35914
25/12/12 03:22:45 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.18.0.5:35921 (size: 508.0 B, free: 4.6 GiB)
25/12/12 03:22:46 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.18.0.5:36293 (size: 508.0 B, free: 4.6 GiB)
25/12/12 03:22:47 INFO TaskSetManager: Starting task 8.0 in stage 41.0 (TID 131) (172.18.0.5, executor 0, partition 8, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:47 INFO TaskSetManager: Finished task 5.0 in stage 41.0 (TID 128) in 1329 ms on 172.18.0.5 (executor 0) (1/12)
25/12/12 03:22:47 INFO TaskSetManager: Starting task 9.0 in stage 41.0 (TID 132) (172.18.0.5, executor 0, partition 9, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:47 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 126) in 1520 ms on 172.18.0.5 (executor 0) (2/12)
25/12/12 03:22:47 INFO TaskSetManager: Starting task 10.0 in stage 41.0 (TID 133) (172.18.0.5, executor 1, partition 10, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:47 INFO TaskSetManager: Finished task 4.0 in stage 41.0 (TID 127) in 1697 ms on 172.18.0.5 (executor 1) (3/12)
25/12/12 03:22:47 INFO TaskSetManager: Starting task 11.0 in stage 41.0 (TID 134) (172.18.0.5, executor 0, partition 11, NODE_LOCAL, 12876 bytes) 
25/12/12 03:22:47 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 124) in 1756 ms on 172.18.0.5 (executor 0) (4/12)
25/12/12 03:22:47 INFO TaskSetManager: Finished task 6.0 in stage 41.0 (TID 129) in 1782 ms on 172.18.0.5 (executor 1) (5/12)
25/12/12 03:22:47 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 123) in 1919 ms on 172.18.0.5 (executor 1) (6/12)
25/12/12 03:22:47 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 125) in 2011 ms on 172.18.0.5 (executor 1) (7/12)
25/12/12 03:22:48 INFO TaskSetManager: Finished task 7.0 in stage 41.0 (TID 130) in 2438 ms on 172.18.0.5 (executor 0) (8/12)
25/12/12 03:22:48 INFO TaskSetManager: Finished task 8.0 in stage 41.0 (TID 131) in 1126 ms on 172.18.0.5 (executor 0) (9/12)
25/12/12 03:22:48 INFO TaskSetManager: Finished task 9.0 in stage 41.0 (TID 132) in 1017 ms on 172.18.0.5 (executor 0) (10/12)
25/12/12 03:22:48 INFO TaskSetManager: Finished task 10.0 in stage 41.0 (TID 133) in 910 ms on 172.18.0.5 (executor 1) (11/12)
25/12/12 03:22:48 INFO TaskSetManager: Finished task 11.0 in stage 41.0 (TID 134) in 1071 ms on 172.18.0.5 (executor 0) (12/12)
25/12/12 03:22:48 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
25/12/12 03:22:48 INFO DAGScheduler: ShuffleMapStage 41 (collect at /app/src/q5.py:175) finished in 2.871 s
25/12/12 03:22:48 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:22:48 INFO DAGScheduler: running: Set()
25/12/12 03:22:48 INFO DAGScheduler: waiting: Set()
25/12/12 03:22:48 INFO DAGScheduler: failed: Set()
25/12/12 03:22:48 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/12/12 03:22:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/12/12 03:22:48 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:22:48 INFO DAGScheduler: Got job 26 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:22:48 INFO DAGScheduler: Final stage: ResultStage 46 (collect at /app/src/q5.py:175)
25/12/12 03:22:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
25/12/12 03:22:48 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:48 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[144] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:48 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 67.6 KiB, free 429.5 MiB)
25/12/12 03:22:48 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 429.4 MiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on spark-master:41121 (size: 29.5 KiB, free: 433.5 MiB)
25/12/12 03:22:48 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[144] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:48 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
25/12/12 03:22:48 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 135) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 12797 bytes) 
25/12/12 03:22:48 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.18.0.5:35921 (size: 29.5 KiB, free: 4.6 GiB)
25/12/12 03:22:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.18.0.5:35906
25/12/12 03:22:48 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 135) in 101 ms on 172.18.0.5 (executor 1) (1/1)
25/12/12 03:22:48 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
25/12/12 03:22:48 INFO DAGScheduler: ResultStage 46 (collect at /app/src/q5.py:175) finished in 0.115 s
25/12/12 03:22:48 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:22:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
25/12/12 03:22:48 INFO DAGScheduler: Job 26 finished: collect at /app/src/q5.py:175, took 0.119040 s
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_52_piece0 on spark-master:41121 in memory (size: 16.8 KiB, free: 433.6 MiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.18.0.5:35921 in memory (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.18.0.5:36293 in memory (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:22:48 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 429.5 MiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on spark-master:41121 (size: 5.4 KiB, free: 433.6 MiB)
25/12/12 03:22:48 INFO SparkContext: Created broadcast 58 from collect at /app/src/q5.py:175
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_53_piece0 on spark-master:41121 in memory (size: 25.7 KiB, free: 433.6 MiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.18.0.5:35921 in memory (size: 25.7 KiB, free: 4.6 GiB)
25/12/12 03:22:48 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_56_piece0 on spark-master:41121 in memory (size: 43.4 KiB, free: 433.6 MiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.18.0.5:35921 in memory (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.18.0.5:36293 in memory (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_55_piece0 on spark-master:41121 in memory (size: 42.2 KiB, free: 433.7 MiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.18.0.5:35921 in memory (size: 42.2 KiB, free: 4.6 GiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_57_piece0 on spark-master:41121 in memory (size: 29.5 KiB, free: 433.7 MiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.18.0.5:35921 in memory (size: 29.5 KiB, free: 4.6 GiB)
25/12/12 03:22:48 INFO CodeGenerator: Code generated in 51.22775 ms
25/12/12 03:22:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/12/12 03:22:48 INFO SparkContext: Starting job: collect at /app/src/q5.py:175
25/12/12 03:22:48 INFO DAGScheduler: Got job 27 (collect at /app/src/q5.py:175) with 1 output partitions
25/12/12 03:22:48 INFO DAGScheduler: Final stage: ResultStage 48 (collect at /app/src/q5.py:175)
25/12/12 03:22:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
25/12/12 03:22:48 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:48 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[149] at collect at /app/src/q5.py:175), which has no missing parents
25/12/12 03:22:48 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 128.6 KiB, free 429.9 MiB)
25/12/12 03:22:48 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 50.3 KiB, free 429.8 MiB)
25/12/12 03:22:48 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on spark-master:41121 (size: 50.3 KiB, free: 433.6 MiB)
25/12/12 03:22:48 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[149] at collect at /app/src/q5.py:175) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:48 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
25/12/12 03:22:48 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 136) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 12797 bytes) 
25/12/12 03:22:48 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.18.0.5:36293 (size: 50.3 KiB, free: 4.6 GiB)
25/12/12 03:22:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.18.0.5:35914
25/12/12 03:22:48 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.18.0.5:36293 (size: 5.4 KiB, free: 4.6 GiB)
25/12/12 03:22:49 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 136) in 68 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:22:49 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
25/12/12 03:22:49 INFO DAGScheduler: ResultStage 48 (collect at /app/src/q5.py:175) finished in 0.075 s
25/12/12 03:22:49 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:22:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
25/12/12 03:22:49 INFO DAGScheduler: Job 27 finished: collect at /app/src/q5.py:175, took 0.078111 s
Correlation (bottom 10 poorest areas): -0.3963502493922934
== Sample per-area statistics (sorted by income) ==
25/12/12 03:22:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:22:49 INFO FileSourceStrategy: Post-Scan Filters: (size(features#189, true) > 0),isnotnull(features#189)
25/12/12 03:22:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Estimated Median Income),IsNotNull(Zip Code)
25/12/12 03:22:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Estimated Median Income#231),isnotnull(Zip Code#229),isnotnull(cast(regexp_replace(Estimated Median Income#231, [$,], , 1) as double))
25/12/12 03:22:49 INFO JoinQueryDetector: Planning spatial join for ST_CONTAINS relationship with swapped left and right shapes
25/12/12 03:22:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(LAT),IsNotNull(LON),Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)),IsNotNull(DATE OCC)
25/12/12 03:22:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(LAT#62),isnotnull(LON#63),NOT (LAT#62 = 0.0),NOT (LON#63 = 0.0),isnotnull(DATE OCC#38),isnotnull(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false))),(year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) >= 2020),(year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) <= 2021),isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )
25/12/12 03:22:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:22:49 INFO FileSourceStrategy: Post-Scan Filters: (size(features#279, true) > 0),isnotnull(features#279)
25/12/12 03:22:49 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 314.0 KiB, free 429.2 MiB)
25/12/12 03:22:49 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 314.0 KiB, free 429.2 MiB)
25/12/12 03:22:49 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 429.2 MiB)
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 433.6 MiB)
25/12/12 03:22:49 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 57.4 KiB, free 429.1 MiB)
25/12/12 03:22:49 INFO SparkContext: Created broadcast 61 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on spark-master:41121 (size: 57.4 KiB, free: 433.5 MiB)
25/12/12 03:22:49 INFO SparkContext: Created broadcast 60 from showString at <unknown>:0
25/12/12 03:22:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:22:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 118509402 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:22:49 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
25/12/12 03:22:49 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
25/12/12 03:22:49 INFO DAGScheduler: Final stage: ResultStage 49 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
25/12/12 03:22:49 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:22:49 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:49 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[157] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
25/12/12 03:22:49 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 19.9 KiB, free 429.1 MiB)
25/12/12 03:22:49 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 429.1 MiB)
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on spark-master:41121 (size: 9.0 KiB, free: 433.5 MiB)
25/12/12 03:22:49 INFO BlockManagerInfo: Removed broadcast_59_piece0 on spark-master:41121 in memory (size: 50.3 KiB, free: 433.6 MiB)
25/12/12 03:22:49 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[157] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:49 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
25/12/12 03:22:49 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 313.8 KiB, free 429.0 MiB)
25/12/12 03:22:49 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 137) (172.18.0.5, executor 1, partition 0, ANY, 13404 bytes) 
25/12/12 03:22:49 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.18.0.5:36293 in memory (size: 50.3 KiB, free: 4.6 GiB)
25/12/12 03:22:49 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 428.9 MiB)
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 433.5 MiB)
25/12/12 03:22:49 INFO SparkContext: Created broadcast 63 from showString at <unknown>:0
25/12/12 03:22:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 22990761 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.18.0.5:35921 (size: 9.0 KiB, free: 4.6 GiB)
25/12/12 03:22:49 INFO SparkContext: Starting job: aggregate at SpatialRDD.java:520
25/12/12 03:22:49 INFO DAGScheduler: Got job 29 (aggregate at SpatialRDD.java:520) with 8 output partitions
25/12/12 03:22:49 INFO DAGScheduler: Final stage: ResultStage 50 (aggregate at SpatialRDD.java:520)
25/12/12 03:22:49 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:22:49 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:49 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[162] at showString at <unknown>:0), which has no missing parents
25/12/12 03:22:49 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 31.2 KiB, free 428.9 MiB)
25/12/12 03:22:49 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 428.9 MiB)
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on spark-master:41121 (size: 14.5 KiB, free: 433.5 MiB)
25/12/12 03:22:49 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:49 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 50 (MapPartitionsRDD[162] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:22:49 INFO TaskSchedulerImpl: Adding task set 50.0 with 8 tasks resource profile 0
25/12/12 03:22:49 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 138) (172.18.0.5, executor 0, partition 0, ANY, 13427 bytes) 
25/12/12 03:22:49 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 139) (172.18.0.5, executor 1, partition 1, ANY, 13427 bytes) 
25/12/12 03:22:49 INFO TaskSetManager: Starting task 2.0 in stage 50.0 (TID 140) (172.18.0.5, executor 0, partition 2, ANY, 13427 bytes) 
25/12/12 03:22:49 INFO TaskSetManager: Starting task 3.0 in stage 50.0 (TID 141) (172.18.0.5, executor 1, partition 3, ANY, 13427 bytes) 
25/12/12 03:22:49 INFO TaskSetManager: Starting task 4.0 in stage 50.0 (TID 142) (172.18.0.5, executor 0, partition 4, ANY, 13427 bytes) 
25/12/12 03:22:49 INFO TaskSetManager: Starting task 5.0 in stage 50.0 (TID 143) (172.18.0.5, executor 1, partition 5, ANY, 13427 bytes) 
25/12/12 03:22:49 INFO TaskSetManager: Starting task 6.0 in stage 50.0 (TID 144) (172.18.0.5, executor 0, partition 6, ANY, 13427 bytes) 
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.18.0.5:35921 (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.18.0.5:36293 (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.18.0.5:35921 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:22:49 INFO TaskSetManager: Starting task 7.0 in stage 50.0 (TID 145) (172.18.0.5, executor 1, partition 7, ANY, 13551 bytes) 
25/12/12 03:22:49 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 137) in 163 ms on 172.18.0.5 (executor 1) (1/1)
25/12/12 03:22:49 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
25/12/12 03:22:49 INFO DAGScheduler: ResultStage 49 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 0.179 s
25/12/12 03:22:49 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:22:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
25/12/12 03:22:49 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 0.181381 s
25/12/12 03:22:49 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 428.8 MiB)
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on spark-master:41121 (size: 5.5 KiB, free: 433.5 MiB)
25/12/12 03:22:49 INFO SparkContext: Created broadcast 65 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.18.0.5:35921 (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:22:49 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.18.0.5:36293 (size: 57.4 KiB, free: 4.6 GiB)
25/12/12 03:22:52 INFO TaskSetManager: Finished task 3.0 in stage 50.0 (TID 141) in 3690 ms on 172.18.0.5 (executor 1) (1/8)
25/12/12 03:22:53 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 139) in 3810 ms on 172.18.0.5 (executor 1) (2/8)
25/12/12 03:22:53 INFO TaskSetManager: Finished task 7.0 in stage 50.0 (TID 145) in 3715 ms on 172.18.0.5 (executor 1) (3/8)
25/12/12 03:22:53 INFO TaskSetManager: Finished task 5.0 in stage 50.0 (TID 143) in 4268 ms on 172.18.0.5 (executor 1) (4/8)
25/12/12 03:22:53 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 138) in 4463 ms on 172.18.0.5 (executor 0) (5/8)
25/12/12 03:22:53 INFO TaskSetManager: Finished task 4.0 in stage 50.0 (TID 142) in 4451 ms on 172.18.0.5 (executor 0) (6/8)
25/12/12 03:22:53 INFO TaskSetManager: Finished task 2.0 in stage 50.0 (TID 140) in 4461 ms on 172.18.0.5 (executor 0) (7/8)
25/12/12 03:22:53 INFO TaskSetManager: Finished task 6.0 in stage 50.0 (TID 144) in 4477 ms on 172.18.0.5 (executor 0) (8/8)
25/12/12 03:22:53 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
25/12/12 03:22:53 INFO DAGScheduler: ResultStage 50 (aggregate at SpatialRDD.java:520) finished in 4.494 s
25/12/12 03:22:53 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:22:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
25/12/12 03:22:53 INFO DAGScheduler: Job 29 finished: aggregate at SpatialRDD.java:520, took 4.503613 s
25/12/12 03:22:53 INFO RangeJoinExec: [SedonaSQL] Number of partitions on the left: 8
25/12/12 03:22:53 INFO RangeJoinExec: [SedonaSQL] Number of partitions on the right: 1
25/12/12 03:22:53 INFO RangeJoinExec: [SedonaSQL] Dominant side count: 407488
25/12/12 03:22:53 INFO SparkContext: Starting job: collect at SpatialRDD.java:269
25/12/12 03:22:53 INFO DAGScheduler: Got job 30 (collect at SpatialRDD.java:269) with 8 output partitions
25/12/12 03:22:53 INFO DAGScheduler: Final stage: ResultStage 51 (collect at SpatialRDD.java:269)
25/12/12 03:22:53 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:22:53 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:53 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[165] at map at SpatialRDD.java:262), which has no missing parents
25/12/12 03:22:53 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 32.1 KiB, free 428.8 MiB)
25/12/12 03:22:53 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 428.8 MiB)
25/12/12 03:22:53 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on spark-master:41121 (size: 15.1 KiB, free: 433.5 MiB)
25/12/12 03:22:53 INFO BlockManagerInfo: Removed broadcast_62_piece0 on spark-master:41121 in memory (size: 9.0 KiB, free: 433.5 MiB)
25/12/12 03:22:53 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:53 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 51 (MapPartitionsRDD[165] at map at SpatialRDD.java:262) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:22:53 INFO TaskSchedulerImpl: Adding task set 51.0 with 8 tasks resource profile 0
25/12/12 03:22:53 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 146) (172.18.0.5, executor 0, partition 0, ANY, 13536 bytes) 
25/12/12 03:22:53 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 147) (172.18.0.5, executor 1, partition 1, ANY, 13536 bytes) 
25/12/12 03:22:53 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 148) (172.18.0.5, executor 0, partition 2, ANY, 13536 bytes) 
25/12/12 03:22:53 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 149) (172.18.0.5, executor 1, partition 3, ANY, 13536 bytes) 
25/12/12 03:22:53 INFO TaskSetManager: Starting task 4.0 in stage 51.0 (TID 150) (172.18.0.5, executor 0, partition 4, ANY, 13536 bytes) 
25/12/12 03:22:53 INFO TaskSetManager: Starting task 5.0 in stage 51.0 (TID 151) (172.18.0.5, executor 1, partition 5, ANY, 13536 bytes) 
25/12/12 03:22:53 INFO TaskSetManager: Starting task 6.0 in stage 51.0 (TID 152) (172.18.0.5, executor 0, partition 6, ANY, 13536 bytes) 
25/12/12 03:22:53 INFO TaskSetManager: Starting task 7.0 in stage 51.0 (TID 153) (172.18.0.5, executor 1, partition 7, ANY, 13660 bytes) 
25/12/12 03:22:53 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.18.0.5:35921 in memory (size: 9.0 KiB, free: 4.6 GiB)
25/12/12 03:22:53 INFO BlockManagerInfo: Removed broadcast_64_piece0 on spark-master:41121 in memory (size: 14.5 KiB, free: 433.5 MiB)
25/12/12 03:22:53 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.18.0.5:35921 in memory (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:22:53 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.18.0.5:36293 in memory (size: 14.5 KiB, free: 4.6 GiB)
25/12/12 03:22:53 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.18.0.5:36293 (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:22:53 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.18.0.5:35921 (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:22:57 INFO TaskSetManager: Finished task 7.0 in stage 51.0 (TID 153) in 3978 ms on 172.18.0.5 (executor 1) (1/8)
25/12/12 03:22:58 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 147) in 4142 ms on 172.18.0.5 (executor 1) (2/8)
25/12/12 03:22:58 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 148) in 4180 ms on 172.18.0.5 (executor 0) (3/8)
25/12/12 03:22:58 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 146) in 4195 ms on 172.18.0.5 (executor 0) (4/8)
25/12/12 03:22:58 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 149) in 4195 ms on 172.18.0.5 (executor 1) (5/8)
25/12/12 03:22:58 INFO TaskSetManager: Finished task 4.0 in stage 51.0 (TID 150) in 4206 ms on 172.18.0.5 (executor 0) (6/8)
25/12/12 03:22:58 INFO TaskSetManager: Finished task 6.0 in stage 51.0 (TID 152) in 4222 ms on 172.18.0.5 (executor 0) (7/8)
25/12/12 03:22:58 INFO TaskSetManager: Finished task 5.0 in stage 51.0 (TID 151) in 4598 ms on 172.18.0.5 (executor 1) (8/8)
25/12/12 03:22:58 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
25/12/12 03:22:58 INFO DAGScheduler: ResultStage 51 (collect at SpatialRDD.java:269) finished in 4.660 s
25/12/12 03:22:58 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:22:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
25/12/12 03:22:58 INFO DAGScheduler: Job 30 finished: collect at SpatialRDD.java:269, took 4.673287 s
25/12/12 03:22:58 INFO SpatialRDD: Collected 4347 samples
25/12/12 03:22:58 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.
25/12/12 03:22:58 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 720.0 B, free 428.9 MiB)
25/12/12 03:22:58 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 505.0 B, free 428.9 MiB)
25/12/12 03:22:58 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on spark-master:41121 (size: 505.0 B, free: 433.5 MiB)
25/12/12 03:22:58 INFO SparkContext: Created broadcast 67 from broadcast at JoinQuery.java:729
25/12/12 03:22:58 INFO DAGScheduler: Registering RDD 166 (flatMapToPair at SpatialRDD.java:361) as input to shuffle 16
25/12/12 03:22:58 INFO DAGScheduler: Registering RDD 169 (flatMapToPair at SpatialRDD.java:361) as input to shuffle 15
25/12/12 03:22:58 INFO DAGScheduler: Registering RDD 177 (showString at <unknown>:0) as input to shuffle 14
25/12/12 03:22:58 INFO DAGScheduler: Got map stage job 31 (showString at <unknown>:0) with 12 output partitions
25/12/12 03:22:58 INFO DAGScheduler: Final stage: ShuffleMapStage 54 (showString at <unknown>:0)
25/12/12 03:22:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52, ShuffleMapStage 53)
25/12/12 03:22:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52, ShuffleMapStage 53)
25/12/12 03:22:58 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[166] at flatMapToPair at SpatialRDD.java:361), which has no missing parents
25/12/12 03:22:58 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 35.5 KiB, free 428.8 MiB)
25/12/12 03:22:58 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 428.8 MiB)
25/12/12 03:22:58 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on spark-master:41121 (size: 16.8 KiB, free: 433.5 MiB)
25/12/12 03:22:58 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:58 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[166] at flatMapToPair at SpatialRDD.java:361) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/12/12 03:22:58 INFO TaskSchedulerImpl: Adding task set 52.0 with 8 tasks resource profile 0
25/12/12 03:22:58 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[169] at flatMapToPair at SpatialRDD.java:361), which has no missing parents
25/12/12 03:22:58 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 154) (172.18.0.5, executor 1, partition 0, ANY, 13416 bytes) 
25/12/12 03:22:58 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 155) (172.18.0.5, executor 0, partition 1, ANY, 13416 bytes) 
25/12/12 03:22:58 INFO TaskSetManager: Starting task 2.0 in stage 52.0 (TID 156) (172.18.0.5, executor 1, partition 2, ANY, 13416 bytes) 
25/12/12 03:22:58 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 81.7 KiB, free 428.7 MiB)
25/12/12 03:22:58 INFO TaskSetManager: Starting task 3.0 in stage 52.0 (TID 157) (172.18.0.5, executor 0, partition 3, ANY, 13416 bytes) 
25/12/12 03:22:58 INFO TaskSetManager: Starting task 4.0 in stage 52.0 (TID 158) (172.18.0.5, executor 1, partition 4, ANY, 13416 bytes) 
25/12/12 03:22:58 INFO TaskSetManager: Starting task 5.0 in stage 52.0 (TID 159) (172.18.0.5, executor 0, partition 5, ANY, 13416 bytes) 
25/12/12 03:22:58 INFO TaskSetManager: Starting task 6.0 in stage 52.0 (TID 160) (172.18.0.5, executor 1, partition 6, ANY, 13416 bytes) 
25/12/12 03:22:58 INFO TaskSetManager: Starting task 7.0 in stage 52.0 (TID 161) (172.18.0.5, executor 0, partition 7, ANY, 13540 bytes) 
25/12/12 03:22:58 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 428.7 MiB)
25/12/12 03:22:58 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on spark-master:41121 (size: 25.7 KiB, free: 433.5 MiB)
25/12/12 03:22:58 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[169] at flatMapToPair at SpatialRDD.java:361) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:58 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
25/12/12 03:22:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:22:58 INFO FileSourceStrategy: Post-Scan Filters: (size(features#189, true) > 0),isnotnull(features#189)
25/12/12 03:22:58 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.18.0.5:36293 (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:22:58 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.18.0.5:35921 (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:22:58 INFO TorrentBroadcast: Started reading broadcast variable 65 with 1 pieces (estimated total size 4.0 MiB)
25/12/12 03:22:58 INFO TorrentBroadcast: Reading broadcast variable 65 took 0 ms
25/12/12 03:22:58 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 313.8 KiB, free 428.4 MiB)
25/12/12 03:22:58 INFO BlockManagerInfo: Removed broadcast_66_piece0 on spark-master:41121 in memory (size: 15.1 KiB, free: 433.5 MiB)
25/12/12 03:22:58 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.18.0.5:36293 in memory (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:22:58 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.18.0.5:35921 in memory (size: 15.1 KiB, free: 4.6 GiB)
25/12/12 03:22:58 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 57.3 KiB, free 428.4 MiB)
25/12/12 03:22:58 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on spark-master:41121 (size: 57.3 KiB, free: 433.4 MiB)
25/12/12 03:22:58 INFO SparkContext: Created broadcast 70 from showString at <unknown>:0
25/12/12 03:22:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 22990761 bytes, open cost is considered as scanning 4194304 bytes.
25/12/12 03:22:58 INFO DAGScheduler: Registering RDD 181 (showString at <unknown>:0) as input to shuffle 17
25/12/12 03:22:58 INFO DAGScheduler: Got map stage job 32 (showString at <unknown>:0) with 1 output partitions
25/12/12 03:22:58 INFO DAGScheduler: Final stage: ShuffleMapStage 55 (showString at <unknown>:0)
25/12/12 03:22:58 INFO DAGScheduler: Parents of final stage: List()
25/12/12 03:22:58 INFO DAGScheduler: Missing parents: List()
25/12/12 03:22:58 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[181] at showString at <unknown>:0), which has no missing parents
25/12/12 03:22:58 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 125.1 KiB, free 428.3 MiB)
25/12/12 03:22:58 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 42.2 KiB, free 428.2 MiB)
25/12/12 03:22:58 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on spark-master:41121 (size: 42.2 KiB, free: 433.4 MiB)
25/12/12 03:22:58 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1580
25/12/12 03:22:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[181] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:22:58 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
25/12/12 03:23:02 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 162) (172.18.0.5, executor 0, partition 0, ANY, 13404 bytes) 
25/12/12 03:23:02 INFO TaskSetManager: Finished task 7.0 in stage 52.0 (TID 161) in 3849 ms on 172.18.0.5 (executor 0) (1/8)
25/12/12 03:23:02 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 163) (172.18.0.5, executor 1, partition 0, ANY, 13404 bytes) 
25/12/12 03:23:02 INFO TaskSetManager: Finished task 4.0 in stage 52.0 (TID 158) in 3856 ms on 172.18.0.5 (executor 1) (2/8)
25/12/12 03:23:02 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 155) in 3985 ms on 172.18.0.5 (executor 0) (3/8)
25/12/12 03:23:02 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.18.0.5:36293 (size: 25.7 KiB, free: 4.6 GiB)
25/12/12 03:23:02 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.18.0.5:35921 (size: 42.2 KiB, free: 4.6 GiB)
25/12/12 03:23:02 INFO TaskSetManager: Finished task 3.0 in stage 52.0 (TID 157) in 4047 ms on 172.18.0.5 (executor 0) (4/8)
25/12/12 03:23:02 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 154) in 4101 ms on 172.18.0.5 (executor 1) (5/8)
25/12/12 03:23:02 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.18.0.5:35921 (size: 5.5 KiB, free: 4.6 GiB)
25/12/12 03:23:02 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.18.0.5:36293 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:23:02 INFO TaskSetManager: Finished task 2.0 in stage 52.0 (TID 156) in 4153 ms on 172.18.0.5 (executor 1) (6/8)
25/12/12 03:23:02 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.18.0.5:35921 (size: 57.3 KiB, free: 4.6 GiB)
25/12/12 03:23:02 INFO TaskSetManager: Finished task 6.0 in stage 52.0 (TID 160) in 4210 ms on 172.18.0.5 (executor 1) (7/8)
25/12/12 03:23:04 INFO TaskSetManager: Finished task 5.0 in stage 52.0 (TID 159) in 5976 ms on 172.18.0.5 (executor 0) (8/8)
25/12/12 03:23:04 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
25/12/12 03:23:04 INFO DAGScheduler: ShuffleMapStage 52 (flatMapToPair at SpatialRDD.java:361) finished in 5.991 s
25/12/12 03:23:04 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:23:04 INFO DAGScheduler: running: Set(ShuffleMapStage 53, ShuffleMapStage 55)
25/12/12 03:23:04 INFO DAGScheduler: waiting: Set(ShuffleMapStage 54)
25/12/12 03:23:04 INFO DAGScheduler: failed: Set()
25/12/12 03:23:12 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 163) in 10447 ms on 172.18.0.5 (executor 1) (1/1)
25/12/12 03:23:12 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
25/12/12 03:23:12 INFO DAGScheduler: ShuffleMapStage 55 (showString at <unknown>:0) finished in 14.085 s
25/12/12 03:23:12 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:23:12 INFO DAGScheduler: running: Set(ShuffleMapStage 53)
25/12/12 03:23:12 INFO DAGScheduler: waiting: Set(ShuffleMapStage 54)
25/12/12 03:23:12 INFO DAGScheduler: failed: Set()
25/12/12 03:23:15 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 162) in 12918 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:23:15 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
25/12/12 03:23:15 INFO DAGScheduler: ShuffleMapStage 53 (flatMapToPair at SpatialRDD.java:361) finished in 16.754 s
25/12/12 03:23:15 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:23:15 INFO DAGScheduler: running: Set()
25/12/12 03:23:15 INFO DAGScheduler: waiting: Set(ShuffleMapStage 54)
25/12/12 03:23:15 INFO DAGScheduler: failed: Set()
25/12/12 03:23:15 INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[177] at showString at <unknown>:0), which has no missing parents
25/12/12 03:23:15 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 120.1 KiB, free 428.1 MiB)
25/12/12 03:23:15 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 43.4 KiB, free 428.1 MiB)
25/12/12 03:23:15 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on spark-master:41121 (size: 43.4 KiB, free: 433.3 MiB)
25/12/12 03:23:15 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1580
25/12/12 03:23:15 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[177] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
25/12/12 03:23:15 INFO TaskSchedulerImpl: Adding task set 54.0 with 12 tasks resource profile 0
25/12/12 03:23:15 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 164) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:15 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 165) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:15 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 166) (172.18.0.5, executor 1, partition 2, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:15 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 167) (172.18.0.5, executor 0, partition 3, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:15 INFO TaskSetManager: Starting task 4.0 in stage 54.0 (TID 168) (172.18.0.5, executor 1, partition 4, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:15 INFO TaskSetManager: Starting task 5.0 in stage 54.0 (TID 169) (172.18.0.5, executor 0, partition 5, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:15 INFO TaskSetManager: Starting task 6.0 in stage 54.0 (TID 170) (172.18.0.5, executor 1, partition 6, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:15 INFO TaskSetManager: Starting task 7.0 in stage 54.0 (TID 171) (172.18.0.5, executor 0, partition 7, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:15 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.18.0.5:35921 (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:23:15 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.18.0.5:36293 (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:23:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.18.0.5:35914
25/12/12 03:23:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.18.0.5:35906
25/12/12 03:23:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.5:35914
25/12/12 03:23:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.5:35906
25/12/12 03:23:15 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.18.0.5:36293 (size: 505.0 B, free: 4.6 GiB)
25/12/12 03:23:15 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.18.0.5:35921 (size: 505.0 B, free: 4.6 GiB)
25/12/12 03:23:16 INFO TaskSetManager: Starting task 8.0 in stage 54.0 (TID 172) (172.18.0.5, executor 0, partition 8, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:16 INFO TaskSetManager: Finished task 5.0 in stage 54.0 (TID 169) in 760 ms on 172.18.0.5 (executor 0) (1/12)
25/12/12 03:23:16 INFO TaskSetManager: Starting task 9.0 in stage 54.0 (TID 173) (172.18.0.5, executor 0, partition 9, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:16 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 167) in 833 ms on 172.18.0.5 (executor 0) (2/12)
25/12/12 03:23:16 INFO TaskSetManager: Starting task 10.0 in stage 54.0 (TID 174) (172.18.0.5, executor 0, partition 10, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:16 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 165) in 868 ms on 172.18.0.5 (executor 0) (3/12)
25/12/12 03:23:16 INFO TaskSetManager: Starting task 11.0 in stage 54.0 (TID 175) (172.18.0.5, executor 1, partition 11, NODE_LOCAL, 12876 bytes) 
25/12/12 03:23:16 INFO TaskSetManager: Finished task 6.0 in stage 54.0 (TID 170) in 1024 ms on 172.18.0.5 (executor 1) (4/12)
25/12/12 03:23:16 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 164) in 1028 ms on 172.18.0.5 (executor 1) (5/12)
25/12/12 03:23:16 INFO TaskSetManager: Finished task 7.0 in stage 54.0 (TID 171) in 1038 ms on 172.18.0.5 (executor 0) (6/12)
25/12/12 03:23:16 INFO TaskSetManager: Finished task 4.0 in stage 54.0 (TID 168) in 1062 ms on 172.18.0.5 (executor 1) (7/12)
25/12/12 03:23:16 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 166) in 1169 ms on 172.18.0.5 (executor 1) (8/12)
25/12/12 03:23:16 INFO TaskSetManager: Finished task 9.0 in stage 54.0 (TID 173) in 477 ms on 172.18.0.5 (executor 0) (9/12)
25/12/12 03:23:16 INFO TaskSetManager: Finished task 10.0 in stage 54.0 (TID 174) in 450 ms on 172.18.0.5 (executor 0) (10/12)
25/12/12 03:23:16 INFO TaskSetManager: Finished task 8.0 in stage 54.0 (TID 172) in 557 ms on 172.18.0.5 (executor 0) (11/12)
25/12/12 03:23:16 INFO TaskSetManager: Finished task 11.0 in stage 54.0 (TID 175) in 515 ms on 172.18.0.5 (executor 1) (12/12)
25/12/12 03:23:16 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
25/12/12 03:23:16 INFO DAGScheduler: ShuffleMapStage 54 (showString at <unknown>:0) finished in 1.581 s
25/12/12 03:23:16 INFO DAGScheduler: looking for newly runnable stages
25/12/12 03:23:16 INFO DAGScheduler: running: Set()
25/12/12 03:23:16 INFO DAGScheduler: waiting: Set()
25/12/12 03:23:16 INFO DAGScheduler: failed: Set()
25/12/12 03:23:16 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/12/12 03:23:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/12/12 03:23:16 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at <unknown>:0
25/12/12 03:23:16 INFO DAGScheduler: Got job 33 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) with 1 output partitions
25/12/12 03:23:16 INFO DAGScheduler: Final stage: ResultStage 59 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0)
25/12/12 03:23:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
25/12/12 03:23:16 INFO DAGScheduler: Missing parents: List()
25/12/12 03:23:16 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[184] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0), which has no missing parents
25/12/12 03:23:17 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 67.6 KiB, free 428.0 MiB)
25/12/12 03:23:17 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 428.0 MiB)
25/12/12 03:23:17 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on spark-master:41121 (size: 29.5 KiB, free: 433.3 MiB)
25/12/12 03:23:17 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1580
25/12/12 03:23:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[184] at $anonfun$withThreadLocalCaptured$1 at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:23:17 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0
25/12/12 03:23:17 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 176) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 12797 bytes) 
25/12/12 03:23:17 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.18.0.5:35921 (size: 29.5 KiB, free: 4.6 GiB)
25/12/12 03:23:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.18.0.5:35906
25/12/12 03:23:17 INFO BlockManagerInfo: Removed broadcast_72_piece0 on spark-master:41121 in memory (size: 43.4 KiB, free: 433.4 MiB)
25/12/12 03:23:17 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.18.0.5:36293 in memory (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:23:17 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.18.0.5:35921 in memory (size: 43.4 KiB, free: 4.6 GiB)
25/12/12 03:23:17 INFO BlockManagerInfo: Removed broadcast_71_piece0 on spark-master:41121 in memory (size: 42.2 KiB, free: 433.4 MiB)
25/12/12 03:23:17 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 176) in 48 ms on 172.18.0.5 (executor 1) (1/1)
25/12/12 03:23:17 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
25/12/12 03:23:17 INFO DAGScheduler: ResultStage 59 ($anonfun$withThreadLocalCaptured$1 at <unknown>:0) finished in 0.057 s
25/12/12 03:23:17 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.18.0.5:35921 in memory (size: 42.2 KiB, free: 4.6 GiB)
25/12/12 03:23:17 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:23:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
25/12/12 03:23:17 INFO DAGScheduler: Job 33 finished: $anonfun$withThreadLocalCaptured$1 at <unknown>:0, took 0.062253 s
25/12/12 03:23:17 INFO BlockManagerInfo: Removed broadcast_69_piece0 on spark-master:41121 in memory (size: 25.7 KiB, free: 433.4 MiB)
25/12/12 03:23:17 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.18.0.5:36293 in memory (size: 25.7 KiB, free: 4.6 GiB)
25/12/12 03:23:17 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 428.4 MiB)
25/12/12 03:23:17 INFO BlockManagerInfo: Removed broadcast_68_piece0 on spark-master:41121 in memory (size: 16.8 KiB, free: 433.4 MiB)
25/12/12 03:23:17 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.18.0.5:36293 in memory (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:23:17 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.18.0.5:35921 in memory (size: 16.8 KiB, free: 4.6 GiB)
25/12/12 03:23:17 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on spark-master:41121 (size: 5.4 KiB, free: 433.4 MiB)
25/12/12 03:23:17 INFO SparkContext: Created broadcast 74 from $anonfun$withThreadLocalCaptured$1 at <unknown>:0
25/12/12 03:23:17 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/12/12 03:23:17 INFO CodeGenerator: Code generated in 16.093083 ms
25/12/12 03:23:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/12/12 03:23:17 INFO CodeGenerator: Code generated in 12.59275 ms
25/12/12 03:23:17 INFO SparkContext: Starting job: showString at <unknown>:0
25/12/12 03:23:17 INFO DAGScheduler: Got job 34 (showString at <unknown>:0) with 1 output partitions
25/12/12 03:23:17 INFO DAGScheduler: Final stage: ResultStage 61 (showString at <unknown>:0)
25/12/12 03:23:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
25/12/12 03:23:17 INFO DAGScheduler: Missing parents: List()
25/12/12 03:23:17 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[188] at showString at <unknown>:0), which has no missing parents
25/12/12 03:23:17 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 102.7 KiB, free 428.4 MiB)
25/12/12 03:23:17 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 42.8 KiB, free 428.3 MiB)
25/12/12 03:23:17 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on spark-master:41121 (size: 42.8 KiB, free: 433.4 MiB)
25/12/12 03:23:17 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1580
25/12/12 03:23:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[188] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/12/12 03:23:17 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
25/12/12 03:23:17 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 177) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 12797 bytes) 
25/12/12 03:23:17 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.18.0.5:36293 (size: 42.8 KiB, free: 4.6 GiB)
25/12/12 03:23:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.18.0.5:35914
25/12/12 03:23:17 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.18.0.5:36293 (size: 5.4 KiB, free: 4.6 GiB)
25/12/12 03:23:17 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 177) in 69 ms on 172.18.0.5 (executor 0) (1/1)
25/12/12 03:23:17 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
25/12/12 03:23:17 INFO DAGScheduler: ResultStage 61 (showString at <unknown>:0) finished in 0.074 s
25/12/12 03:23:17 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
25/12/12 03:23:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
25/12/12 03:23:17 INFO DAGScheduler: Job 34 finished: showString at <unknown>:0, took 0.076148 s
25/12/12 03:23:17 INFO CodeGenerator: Code generated in 5.668083 ms
25/12/12 03:23:17 INFO CodeGenerator: Code generated in 4.784292 ms
+--------------------------------------+----------+------------------+---------------------+
|COMM                                  |population|income_pc         |annual_crime_rate    |
+--------------------------------------+----------+------------------+---------------------+
|Palisades Highlands                   |3911.0    |212115.0          |0.013935054973152646 |
|Pacific Palisades                     |20952.0   |201948.38320924016|0.030211912943871707 |
|Westfield/Academy Hills               |1396.0    |186144.0          |0.0                  |
|Palos Verdes Peninsula                |719.0     |186144.0          |0.0                  |
|Bel Air                               |7748.0    |185439.21011874033|0.03304078471863707  |
|Mandeville Canyon                     |3242.0    |163295.3362122147 |0.015885256014805674 |
|Beverly Crest                         |11918.0   |155926.5159422722 |0.025801308944453767 |
|Franklin Canyon                       |1.0       |154740.0          |0.0                  |
|Playa Vista                           |16230.0   |151284.56796056684|0.030776340110905732 |
|Santa Monica Mountains                |16417.0   |146976.57629286716|3.0456234391179874E-5|
|Stevenson Ranch                       |20968.0   |144310.41157954978|0.0                  |
|Brentwood                             |30334.0   |142907.47633019055|0.0300817564449133   |
|Marina del Rey                        |11342.0   |137813.0          |7.053429730206313E-4 |
|Marina Peninsula                      |4903.0    |137813.0          |0.047521925351825416 |
|Valencia                              |3359.0    |136229.0          |0.0                  |
|Saugus                                |640.0     |133150.0          |0.0                  |
|San Francisquito Canyon/Bouquet Canyon|325.0     |133150.0          |0.0                  |
|Agua Dulce                            |4120.0    |132433.30388349516|0.0                  |
|Bouquet Canyon                        |1105.0    |131979.0923076923 |0.0                  |
|Saugus/Canyon Country                 |484.0     |130429.23760330578|0.0                  |
+--------------------------------------+----------+------------------+---------------------+
only showing top 20 rows

== Physical plan for final aggregation (joins) ==
25/12/12 03:23:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:23:17 INFO FileSourceStrategy: Post-Scan Filters: (size(features#189, true) > 0),isnotnull(features#189)
25/12/12 03:23:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Estimated Median Income),IsNotNull(Zip Code)
25/12/12 03:23:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Estimated Median Income#231),isnotnull(Zip Code#229),isnotnull(cast(regexp_replace(Estimated Median Income#231, [$,], , 1) as double))
25/12/12 03:23:17 INFO JoinQueryDetector: Planning spatial join for ST_CONTAINS relationship with swapped left and right shapes
25/12/12 03:23:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(LAT),IsNotNull(LON),Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)),IsNotNull(DATE OCC)
25/12/12 03:23:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(LAT#62),isnotnull(LON#63),NOT (LAT#62 = 0.0),NOT (LON#63 = 0.0),isnotnull(DATE OCC#38),isnotnull(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false))),(year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) >= 2020),(year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) <= 2021),isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  )
25/12/12 03:23:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(features)
25/12/12 03:23:17 INFO FileSourceStrategy: Post-Scan Filters: (size(features#279, true) > 0),isnotnull(features#279)
== Physical Plan ==
AdaptiveSparkPlan (34)
+- Project (33)
   +- Project (32)
      +- SortMergeJoin LeftOuter (31)
         :- Sort (16)
         :  +- Filter (15)
         :     +- HashAggregate (14)
         :        +- Exchange (13)
         :           +- HashAggregate (12)
         :              +- Project (11)
         :                 +- BroadcastHashJoin Inner BuildRight (10)
         :                    :- Project (5)
         :                    :  +- Filter (4)
         :                    :     +- Generate (3)
         :                    :        +- Filter (2)
         :                    :           +- Scan json  (1)
         :                    +- BroadcastExchange (9)
         :                       +- Project (8)
         :                          +- Filter (7)
         :                             +- Scan csv  (6)
         +- Sort (30)
            +- HashAggregate (29)
               +- Exchange (28)
                  +- HashAggregate (27)
                     +- Project (26)
                        +- RangeJoin (25)
                           :- Project (19)
                           :  +- Filter (18)
                           :     +- Scan csv  (17)
                           +- Project (24)
                              +- Filter (23)
                                 +- Generate (22)
                                    +- Filter (21)
                                       +- Scan json  (20)


(1) Scan json 
Output [1]: [features#189]
Batched: false
Location: InMemoryFileIndex [hdfs://namenode:9000/data/LA_Census_Blocks_2020.geojson]
PushedFilters: [IsNotNull(features)]
ReadSchema: struct<features:array<struct<geometry:struct<coordinates:array<array<array<string>>>,type:string>,properties:struct<BG20:string,BG20FIP_CURRENT:string,BGFIP20:string,CB20:string,CITY:string,CITYCOMM:string,CITYCOMM_CURRENT:string,CITY_CURRENT:string,COMM:string,COMM_CURRENT:string,COUNTY:string,CT20:string,CTCB20:string,FEAT_TYPE:string,FIP20:string,FIP_CURRENT:string,HD22:bigint,HD_NAME:string,HOUSING20:bigint,OBJECTID:bigint,POP20:bigint,SPA22:bigint,SPA_NAME:string,SUP21:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,State:string,ZCTA20:string>,type:string>>>

(2) Filter
Input [1]: [features#189]
Condition : ((size(features#189, true) > 0) AND isnotnull(features#189))

(3) Generate
Input [1]: [features#189]
Arguments: explode(features#189), false, [feature#197]

(4) Filter
Input [1]: [feature#197]
Condition : (isnotnull(feature#197.properties.POP20) AND (((isnotnull(feature#197.properties.COMM) AND isnotnull(feature#197.properties.ZCTA20)) AND isnotnull(cast(feature#197.properties.POP20 as double))) AND (cast(feature#197.properties.POP20 as double) > 0.0)))

(5) Project
Output [3]: [feature#197.properties.COMM AS COMM#200, feature#197.properties.ZCTA20 AS zip_code#201, cast(feature#197.properties.POP20 as double) AS population#202]
Input [1]: [feature#197]

(6) Scan csv 
Output [2]: [Zip Code#229, Estimated Median Income#231]
Batched: false
Location: InMemoryFileIndex [hdfs://namenode:9000/data/LA_income_2021.csv]
PushedFilters: [IsNotNull(Estimated Median Income), IsNotNull(Zip Code)]
ReadSchema: struct<Zip Code:string,Estimated Median Income:string>

(7) Filter
Input [2]: [Zip Code#229, Estimated Median Income#231]
Condition : ((isnotnull(Estimated Median Income#231) AND isnotnull(Zip Code#229)) AND isnotnull(cast(regexp_replace(Estimated Median Income#231, [$,], , 1) as double)))

(8) Project
Output [2]: [Zip Code#229 AS zip_code#235, cast(regexp_replace(Estimated Median Income#231, [$,], , 1) as double) AS income_pc#236]
Input [2]: [Zip Code#229, Estimated Median Income#231]

(9) BroadcastExchange
Input [2]: [zip_code#235, income_pc#236]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=2138]

(10) BroadcastHashJoin
Left keys [1]: [zip_code#201]
Right keys [1]: [zip_code#235]
Join type: Inner
Join condition: None

(11) Project
Output [3]: [COMM#200, population#202, income_pc#236]
Input [5]: [COMM#200, zip_code#201, population#202, zip_code#235, income_pc#236]

(12) HashAggregate
Input [3]: [COMM#200, population#202, income_pc#236]
Keys [1]: [COMM#200]
Functions [2]: [partial_sum(population#202), partial_sum((population#202 * income_pc#236))]
Aggregate Attributes [2]: [sum#342, sum#343]
Results [3]: [COMM#200, sum#344, sum#345]

(13) Exchange
Input [3]: [COMM#200, sum#344, sum#345]
Arguments: hashpartitioning(COMM#200, 32), ENSURE_REQUIREMENTS, [plan_id=2143]

(14) HashAggregate
Input [3]: [COMM#200, sum#344, sum#345]
Keys [1]: [COMM#200]
Functions [2]: [sum(population#202), sum((population#202 * income_pc#236))]
Aggregate Attributes [2]: [sum(population#202)#270, sum((population#202 * income_pc#236))#272]
Results [3]: [COMM#200, sum(population#202)#270 AS population#271, (sum((population#202 * income_pc#236))#272 / sum(population#202)#270) AS income_pc#274]

(15) Filter
Input [3]: [COMM#200, population#271, income_pc#274]
Condition : (isnotnull(population#271) AND ((population#271 > 0.0) AND isnotnull(income_pc#274)))

(16) Sort
Input [3]: [COMM#200, population#271, income_pc#274]
Arguments: [COMM#200 ASC NULLS FIRST], false, 0

(17) Scan csv 
Output [3]: [DATE OCC#38, LAT#62, LON#63]
Batched: false
Location: InMemoryFileIndex [hdfs://namenode:9000/data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv, ... 1 entries]
PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Not(EqualTo(LAT,0.0)), Not(EqualTo(LON,0.0)), IsNotNull(DATE OCC)]
ReadSchema: struct<DATE OCC:string,LAT:double,LON:double>

(18) Filter
Input [3]: [DATE OCC#38, LAT#62, LON#63]
Condition : ((((((((isnotnull(LAT#62) AND isnotnull(LON#63)) AND NOT (LAT#62 = 0.0)) AND NOT (LON#63 = 0.0)) AND isnotnull(DATE OCC#38)) AND isnotnull(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)))) AND (year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) >= 2020)) AND (year(cast(coalesce(gettimestamp(DATE OCC#38, yyyy MMM dd hh:mm:ss a, TimestampType, Some(Etc/UTC), false), gettimestamp(DATE OCC#38, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Etc/UTC), false)) as date)) <= 2021)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))

(19) Project
Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geom#154]
Input [3]: [DATE OCC#38, LAT#62, LON#63]

(20) Scan json 
Output [1]: [features#279]
Batched: false
Location: InMemoryFileIndex [hdfs://namenode:9000/data/LA_Census_Blocks_2020.geojson]
PushedFilters: [IsNotNull(features)]
ReadSchema: struct<features:array<struct<geometry:struct<coordinates:array<array<array<string>>>,type:string>,properties:struct<BG20:string,BG20FIP_CURRENT:string,BGFIP20:string,CB20:string,CITY:string,CITYCOMM:string,CITYCOMM_CURRENT:string,CITY_CURRENT:string,COMM:string,COMM_CURRENT:string,COUNTY:string,CT20:string,CTCB20:string,FEAT_TYPE:string,FIP20:string,FIP_CURRENT:string,HD22:bigint,HD_NAME:string,HOUSING20:bigint,OBJECTID:bigint,POP20:bigint,SPA22:bigint,SPA_NAME:string,SUP21:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,State:string,ZCTA20:string>,type:string>>>

(21) Filter
Input [1]: [features#279]
Condition : ((size(features#279, true) > 0) AND isnotnull(features#279))

(22) Generate
Input [1]: [features#279]
Arguments: explode(features#279), false, [feature#197]

(23) Filter
Input [1]: [feature#197]
Condition : (isnotnull(feature#197.properties.POP20) AND (((isnotnull(feature#197.properties.COMM) AND isnotnull(feature#197.properties.ZCTA20)) AND isnotnull(cast(feature#197.properties.POP20 as double))) AND (cast(feature#197.properties.POP20 as double) > 0.0)))

(24) Project
Output [2]: [feature#197.properties.COMM AS COMM#200, st_geomfromgeojson(to_json(feature#197.geometry, Some(Etc/UTC))) AS geom#203]
Input [1]: [feature#197]

(25) RangeJoin
Arguments: geom#154: geometry, geom#203: geometry, WITHIN

(26) Project
Output [1]: [COMM#200 AS COMM#250]
Input [3]: [geom#154, COMM#200, geom#203]

(27) HashAggregate
Input [1]: [COMM#250]
Keys [1]: [COMM#250]
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#346L]
Results [2]: [COMM#250, count#347L]

(28) Exchange
Input [2]: [COMM#250, count#347L]
Arguments: hashpartitioning(COMM#250, 32), ENSURE_REQUIREMENTS, [plan_id=2146]

(29) HashAggregate
Input [2]: [COMM#250, count#347L]
Keys [1]: [COMM#250]
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#256L]
Results [2]: [COMM#250, count(1)#256L AS crimes_2020_2021#257L]

(30) Sort
Input [2]: [COMM#250, crimes_2020_2021#257L]
Arguments: [COMM#250 ASC NULLS FIRST], false, 0

(31) SortMergeJoin
Left keys [1]: [COMM#200]
Right keys [1]: [COMM#250]
Join type: LeftOuter
Join condition: None

(32) Project
Output [4]: [COMM#200, population#271, income_pc#274, coalesce(crimes_2020_2021#257L, 0) AS crimes_2020_2021#291L]
Input [5]: [COMM#200, population#271, income_pc#274, COMM#250, crimes_2020_2021#257L]

(33) Project
Output [5]: [COMM#200, population#271, income_pc#274, crimes_2020_2021#291L, (cast(crimes_2020_2021#291L as double) / (population#271 * 2.0)) AS annual_crime_rate#296]
Input [4]: [COMM#200, population#271, income_pc#274, crimes_2020_2021#291L]

(34) AdaptiveSparkPlan
Output [5]: [COMM#200, population#271, income_pc#274, crimes_2020_2021#291L, annual_crime_rate#296]
Arguments: isFinalPlan=false


Execution time for q5 with 2 executors, 4 cores, 8g memory: 119.06206 seconds
25/12/12 03:23:17 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/12/12 03:23:17 INFO SparkUI: Stopped Spark web UI at http://spark-master:4040
25/12/12 03:23:17 INFO StandaloneSchedulerBackend: Shutting down all executors
25/12/12 03:23:17 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/12/12 03:23:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/12/12 03:23:17 INFO MemoryStore: MemoryStore cleared
25/12/12 03:23:17 INFO BlockManager: BlockManager stopped
25/12/12 03:23:17 INFO BlockManagerMaster: BlockManagerMaster stopped
25/12/12 03:23:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/12/12 03:23:17 INFO SparkContext: Successfully stopped SparkContext
25/12/12 03:23:18 INFO ShutdownHookManager: Shutdown hook called
25/12/12 03:23:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-49ead383-6f18-449b-b736-3276aed89eb5
25/12/12 03:23:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9
25/12/12 03:23:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-e98255c9-d6c3-4541-b908-e8fb906262a9/pyspark-89397f9e-1a7a-46cd-87a6-1be0f92ecd72
